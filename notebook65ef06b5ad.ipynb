{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Xeena2812/onallo-labor/blob/original-inceptionv4/notebook65ef06b5ad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the CIFAR-100 dataset"
      ],
      "metadata": {
        "id": "TTmR8YkdAnem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data(label_mode='fine')\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2023-04-27T13:54:32.611701Z",
          "iopub.execute_input": "2023-04-27T13:54:32.612378Z",
          "iopub.status.idle": "2023-04-27T13:54:48.698593Z",
          "shell.execute_reply.started": "2023-04-27T13:54:32.612338Z",
          "shell.execute_reply": "2023-04-27T13:54:48.697284Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCEUIipqAneo",
        "outputId": "7839a1b4-25d1-4006-9432-b622c9b6c5f3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 11s 0us/step\n",
            "(50000, 32, 32, 3) (50000, 1)\n",
            "(10000, 32, 32, 3) (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.config.list_physical_devices('GPU'))\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-26T18:20:24.870978Z",
          "iopub.execute_input": "2023-04-26T18:20:24.871665Z",
          "iopub.status.idle": "2023-04-26T18:20:26.088566Z",
          "shell.execute_reply.started": "2023-04-26T18:20:24.871629Z",
          "shell.execute_reply": "2023-04-26T18:20:26.087373Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ffb4_nhvAneq",
        "outputId": "f35addfe-6d73-4937-ec62-c66b3d90a77c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Thu Apr 27 14:33:14 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8    12W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.data import Dataset\n",
        "from keras.layers import Resizing, Rescaling\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "enc = LabelBinarizer()\n",
        "\n",
        "y_train = enc.fit_transform(y_train)\n",
        "y_test = enc.fit_transform(y_test)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "#x_train = np.moveaxis(x_train, -1, 1)\n",
        "#x_test = np.moveaxis(x_test, -1, 1)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-27T13:54:57.514936Z",
          "iopub.execute_input": "2023-04-27T13:54:57.515674Z",
          "iopub.status.idle": "2023-04-27T13:54:57.937209Z",
          "shell.execute_reply.started": "2023-04-27T13:54:57.515633Z",
          "shell.execute_reply": "2023-04-27T13:54:57.935894Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nBj2aCTAner",
        "outputId": "2725d38d-c881-4672-e07b-0f5e90bb7c3b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inception v4 Implementation"
      ],
      "metadata": {
        "id": "PNGSo6VaAnes"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Concatenate, Input\n",
        "from keras.metrics import TopKCategoricalAccuracy\n",
        "\n",
        "resize_rescale = tf.keras.Sequential([\n",
        "    Input(shape=(32, 32, 3)),\n",
        "    Resizing(299, 299),\n",
        "    Rescaling(1./255, offset=-1),\n",
        "])\n",
        "# create the base pre-trained model\n",
        "base_model = InceptionV3(input_tensor=resize_rescale.output, weights='imagenet', include_top=False)\n",
        "\n",
        "\n",
        "# add own top to pre-trained model\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "\n",
        "predictions = Dense(100, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# first train only the top layers\n",
        "# freeze all convolutional InceptionV3 layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "              metrics=[\n",
        "                  TopKCategoricalAccuracy(k=1, name='top_1_accuracy'),\n",
        "                  TopKCategoricalAccuracy(k=5, name='top_5_accuracy'),\n",
        "              ])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-27T13:55:22.181554Z",
          "iopub.execute_input": "2023-04-27T13:55:22.182224Z",
          "iopub.status.idle": "2023-04-27T13:55:28.162373Z",
          "shell.execute_reply.started": "2023-04-27T13:55:22.182186Z",
          "shell.execute_reply": "2023-04-27T13:55:28.161356Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXhgqj3KAnes",
        "outputId": "f3d6bbc6-e1e2-47bf-86ad-19f18e59b0b1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(cm, class_names):\n",
        "  \"\"\"\n",
        "  Returns a matplotlib figure containing the plotted confusion matrix.\n",
        "\n",
        "  Args:\n",
        "    cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
        "    class_names (array, shape = [n]): String names of the integer classes\n",
        "  \"\"\"\n",
        "  figure = plt.figure(figsize=(8, 8))\n",
        "  plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "  plt.title(\"Confusion matrix\")\n",
        "  plt.colorbar()\n",
        "  tick_marks = np.arange(len(class_names))\n",
        "  plt.xticks(tick_marks, class_names, rotation=45)\n",
        "  plt.yticks(tick_marks, class_names)\n",
        "\n",
        "  # Compute the labels from the normalized confusion matrix.\n",
        "  labels = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
        "\n",
        "  # Use white text if squares are dark; otherwise black.\n",
        "  threshold = cm.max() / 2.\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    color = \"white\" if cm[i, j] > threshold else \"black\"\n",
        "    plt.text(j, i, labels[i, j], horizontalalignment=\"center\", color=color)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')\n",
        "  return figure\n",
        "\n",
        "\n",
        "def log_confusion_matrix(epoch, logs):\n",
        "  # Use the model to predict the values from the validation dataset.\n",
        "  test_pred_raw = model.predict(x_test)\n",
        "  test_pred = np.argmax(test_pred_raw, axis=1)\n",
        "\n",
        "  # Calculate the confusion matrix.\n",
        "  cm = sklearn.metrics.confusion_matrix(y_test, test_pred)\n",
        "  # Log the confusion matrix as an image summary.\n",
        "  figure = plot_confusion_matrix(cm, class_names=np.arange(100))\n",
        "  cm_image = plot_to_image(figure)\n",
        "\n",
        "  # Log the confusion matrix as an image summary.\n",
        "  with file_writer_cm.as_default():\n",
        "    tf.summary.image(\"epoch_confusion_matrix\", cm_image, step=epoch)\n",
        "\n",
        "def plot_to_image(figure):\n",
        "  \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
        "  returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
        "  # Save the plot to a PNG in memory.\n",
        "  buf = io.BytesIO()\n",
        "  plt.savefig(buf, format='png')\n",
        "  # Closing the figure prevents it from being displayed directly inside\n",
        "  # the notebook.\n",
        "  plt.close(figure)\n",
        "  buf.seek(0)\n",
        "  # Convert PNG buffer to TF image\n",
        "  image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
        "  # Add the batch dimension\n",
        "  image = tf.expand_dims(image, 0)\n",
        "  return image"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-27T13:56:44.668357Z",
          "iopub.execute_input": "2023-04-27T13:56:44.669308Z",
          "iopub.status.idle": "2023-04-27T13:56:44.683052Z",
          "shell.execute_reply.started": "2023-04-27T13:56:44.669253Z",
          "shell.execute_reply": "2023-04-27T13:56:44.682007Z"
        },
        "trusted": true,
        "id": "p6LOiOCIAnet"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's visualize layer names and layer indices to see how many layers\n",
        "# we should freeze:\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "   print(i, layer.name)\n",
        "\n",
        "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
        "# the first 249 layers and unfreeze the rest:\n",
        "for layer in model.layers[:249]:\n",
        "   layer.trainable = False\n",
        "for layer in model.layers[249:]:\n",
        "   layer.trainable = True\n",
        "\n",
        "# we need to recompile the model for these modifications to take effect\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "              metrics=[\n",
        "                  TopKCategoricalAccuracy(k=1, name='top_1_accuracy'),\n",
        "                  TopKCategoricalAccuracy(k=5, name='top_5_accuracy'),\n",
        "              ])\n",
        "# run previous block to train model again, but with more epochs"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obMpMME6Anet",
        "outputId": "fbb02d83-6987-41fa-8713-f95a4f3a047a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_1\n",
            "1 resizing\n",
            "2 rescaling\n",
            "3 conv2d\n",
            "4 batch_normalization\n",
            "5 activation\n",
            "6 conv2d_1\n",
            "7 batch_normalization_1\n",
            "8 activation_1\n",
            "9 conv2d_2\n",
            "10 batch_normalization_2\n",
            "11 activation_2\n",
            "12 max_pooling2d\n",
            "13 conv2d_3\n",
            "14 batch_normalization_3\n",
            "15 activation_3\n",
            "16 conv2d_4\n",
            "17 batch_normalization_4\n",
            "18 activation_4\n",
            "19 max_pooling2d_1\n",
            "20 conv2d_8\n",
            "21 batch_normalization_8\n",
            "22 activation_8\n",
            "23 conv2d_6\n",
            "24 conv2d_9\n",
            "25 batch_normalization_6\n",
            "26 batch_normalization_9\n",
            "27 activation_6\n",
            "28 activation_9\n",
            "29 average_pooling2d\n",
            "30 conv2d_5\n",
            "31 conv2d_7\n",
            "32 conv2d_10\n",
            "33 conv2d_11\n",
            "34 batch_normalization_5\n",
            "35 batch_normalization_7\n",
            "36 batch_normalization_10\n",
            "37 batch_normalization_11\n",
            "38 activation_5\n",
            "39 activation_7\n",
            "40 activation_10\n",
            "41 activation_11\n",
            "42 mixed0\n",
            "43 conv2d_15\n",
            "44 batch_normalization_15\n",
            "45 activation_15\n",
            "46 conv2d_13\n",
            "47 conv2d_16\n",
            "48 batch_normalization_13\n",
            "49 batch_normalization_16\n",
            "50 activation_13\n",
            "51 activation_16\n",
            "52 average_pooling2d_1\n",
            "53 conv2d_12\n",
            "54 conv2d_14\n",
            "55 conv2d_17\n",
            "56 conv2d_18\n",
            "57 batch_normalization_12\n",
            "58 batch_normalization_14\n",
            "59 batch_normalization_17\n",
            "60 batch_normalization_18\n",
            "61 activation_12\n",
            "62 activation_14\n",
            "63 activation_17\n",
            "64 activation_18\n",
            "65 mixed1\n",
            "66 conv2d_22\n",
            "67 batch_normalization_22\n",
            "68 activation_22\n",
            "69 conv2d_20\n",
            "70 conv2d_23\n",
            "71 batch_normalization_20\n",
            "72 batch_normalization_23\n",
            "73 activation_20\n",
            "74 activation_23\n",
            "75 average_pooling2d_2\n",
            "76 conv2d_19\n",
            "77 conv2d_21\n",
            "78 conv2d_24\n",
            "79 conv2d_25\n",
            "80 batch_normalization_19\n",
            "81 batch_normalization_21\n",
            "82 batch_normalization_24\n",
            "83 batch_normalization_25\n",
            "84 activation_19\n",
            "85 activation_21\n",
            "86 activation_24\n",
            "87 activation_25\n",
            "88 mixed2\n",
            "89 conv2d_27\n",
            "90 batch_normalization_27\n",
            "91 activation_27\n",
            "92 conv2d_28\n",
            "93 batch_normalization_28\n",
            "94 activation_28\n",
            "95 conv2d_26\n",
            "96 conv2d_29\n",
            "97 batch_normalization_26\n",
            "98 batch_normalization_29\n",
            "99 activation_26\n",
            "100 activation_29\n",
            "101 max_pooling2d_2\n",
            "102 mixed3\n",
            "103 conv2d_34\n",
            "104 batch_normalization_34\n",
            "105 activation_34\n",
            "106 conv2d_35\n",
            "107 batch_normalization_35\n",
            "108 activation_35\n",
            "109 conv2d_31\n",
            "110 conv2d_36\n",
            "111 batch_normalization_31\n",
            "112 batch_normalization_36\n",
            "113 activation_31\n",
            "114 activation_36\n",
            "115 conv2d_32\n",
            "116 conv2d_37\n",
            "117 batch_normalization_32\n",
            "118 batch_normalization_37\n",
            "119 activation_32\n",
            "120 activation_37\n",
            "121 average_pooling2d_3\n",
            "122 conv2d_30\n",
            "123 conv2d_33\n",
            "124 conv2d_38\n",
            "125 conv2d_39\n",
            "126 batch_normalization_30\n",
            "127 batch_normalization_33\n",
            "128 batch_normalization_38\n",
            "129 batch_normalization_39\n",
            "130 activation_30\n",
            "131 activation_33\n",
            "132 activation_38\n",
            "133 activation_39\n",
            "134 mixed4\n",
            "135 conv2d_44\n",
            "136 batch_normalization_44\n",
            "137 activation_44\n",
            "138 conv2d_45\n",
            "139 batch_normalization_45\n",
            "140 activation_45\n",
            "141 conv2d_41\n",
            "142 conv2d_46\n",
            "143 batch_normalization_41\n",
            "144 batch_normalization_46\n",
            "145 activation_41\n",
            "146 activation_46\n",
            "147 conv2d_42\n",
            "148 conv2d_47\n",
            "149 batch_normalization_42\n",
            "150 batch_normalization_47\n",
            "151 activation_42\n",
            "152 activation_47\n",
            "153 average_pooling2d_4\n",
            "154 conv2d_40\n",
            "155 conv2d_43\n",
            "156 conv2d_48\n",
            "157 conv2d_49\n",
            "158 batch_normalization_40\n",
            "159 batch_normalization_43\n",
            "160 batch_normalization_48\n",
            "161 batch_normalization_49\n",
            "162 activation_40\n",
            "163 activation_43\n",
            "164 activation_48\n",
            "165 activation_49\n",
            "166 mixed5\n",
            "167 conv2d_54\n",
            "168 batch_normalization_54\n",
            "169 activation_54\n",
            "170 conv2d_55\n",
            "171 batch_normalization_55\n",
            "172 activation_55\n",
            "173 conv2d_51\n",
            "174 conv2d_56\n",
            "175 batch_normalization_51\n",
            "176 batch_normalization_56\n",
            "177 activation_51\n",
            "178 activation_56\n",
            "179 conv2d_52\n",
            "180 conv2d_57\n",
            "181 batch_normalization_52\n",
            "182 batch_normalization_57\n",
            "183 activation_52\n",
            "184 activation_57\n",
            "185 average_pooling2d_5\n",
            "186 conv2d_50\n",
            "187 conv2d_53\n",
            "188 conv2d_58\n",
            "189 conv2d_59\n",
            "190 batch_normalization_50\n",
            "191 batch_normalization_53\n",
            "192 batch_normalization_58\n",
            "193 batch_normalization_59\n",
            "194 activation_50\n",
            "195 activation_53\n",
            "196 activation_58\n",
            "197 activation_59\n",
            "198 mixed6\n",
            "199 conv2d_64\n",
            "200 batch_normalization_64\n",
            "201 activation_64\n",
            "202 conv2d_65\n",
            "203 batch_normalization_65\n",
            "204 activation_65\n",
            "205 conv2d_61\n",
            "206 conv2d_66\n",
            "207 batch_normalization_61\n",
            "208 batch_normalization_66\n",
            "209 activation_61\n",
            "210 activation_66\n",
            "211 conv2d_62\n",
            "212 conv2d_67\n",
            "213 batch_normalization_62\n",
            "214 batch_normalization_67\n",
            "215 activation_62\n",
            "216 activation_67\n",
            "217 average_pooling2d_6\n",
            "218 conv2d_60\n",
            "219 conv2d_63\n",
            "220 conv2d_68\n",
            "221 conv2d_69\n",
            "222 batch_normalization_60\n",
            "223 batch_normalization_63\n",
            "224 batch_normalization_68\n",
            "225 batch_normalization_69\n",
            "226 activation_60\n",
            "227 activation_63\n",
            "228 activation_68\n",
            "229 activation_69\n",
            "230 mixed7\n",
            "231 conv2d_72\n",
            "232 batch_normalization_72\n",
            "233 activation_72\n",
            "234 conv2d_73\n",
            "235 batch_normalization_73\n",
            "236 activation_73\n",
            "237 conv2d_70\n",
            "238 conv2d_74\n",
            "239 batch_normalization_70\n",
            "240 batch_normalization_74\n",
            "241 activation_70\n",
            "242 activation_74\n",
            "243 conv2d_71\n",
            "244 conv2d_75\n",
            "245 batch_normalization_71\n",
            "246 batch_normalization_75\n",
            "247 activation_71\n",
            "248 activation_75\n",
            "249 max_pooling2d_3\n",
            "250 mixed8\n",
            "251 conv2d_80\n",
            "252 batch_normalization_80\n",
            "253 activation_80\n",
            "254 conv2d_77\n",
            "255 conv2d_81\n",
            "256 batch_normalization_77\n",
            "257 batch_normalization_81\n",
            "258 activation_77\n",
            "259 activation_81\n",
            "260 conv2d_78\n",
            "261 conv2d_79\n",
            "262 conv2d_82\n",
            "263 conv2d_83\n",
            "264 average_pooling2d_7\n",
            "265 conv2d_76\n",
            "266 batch_normalization_78\n",
            "267 batch_normalization_79\n",
            "268 batch_normalization_82\n",
            "269 batch_normalization_83\n",
            "270 conv2d_84\n",
            "271 batch_normalization_76\n",
            "272 activation_78\n",
            "273 activation_79\n",
            "274 activation_82\n",
            "275 activation_83\n",
            "276 batch_normalization_84\n",
            "277 activation_76\n",
            "278 mixed9_0\n",
            "279 concatenate\n",
            "280 activation_84\n",
            "281 mixed9\n",
            "282 conv2d_89\n",
            "283 batch_normalization_89\n",
            "284 activation_89\n",
            "285 conv2d_86\n",
            "286 conv2d_90\n",
            "287 batch_normalization_86\n",
            "288 batch_normalization_90\n",
            "289 activation_86\n",
            "290 activation_90\n",
            "291 conv2d_87\n",
            "292 conv2d_88\n",
            "293 conv2d_91\n",
            "294 conv2d_92\n",
            "295 average_pooling2d_8\n",
            "296 conv2d_85\n",
            "297 batch_normalization_87\n",
            "298 batch_normalization_88\n",
            "299 batch_normalization_91\n",
            "300 batch_normalization_92\n",
            "301 conv2d_93\n",
            "302 batch_normalization_85\n",
            "303 activation_87\n",
            "304 activation_88\n",
            "305 activation_91\n",
            "306 activation_92\n",
            "307 batch_normalization_93\n",
            "308 activation_85\n",
            "309 mixed9_1\n",
            "310 concatenate_1\n",
            "311 activation_93\n",
            "312 mixed10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, TerminateOnNaN\n",
        "import datetime\n",
        "\n",
        "logdir = \"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
        "\n",
        "# at this point, the top layers are well trained and we can start fine-tuning\n",
        "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
        "# and train the remaining top layers.\n",
        "model.fit(x_train, y_train,\n",
        "          epochs=200,\n",
        "          batch_size=512,\n",
        "          validation_batch_size=512,\n",
        "          callbacks=[\n",
        "              TensorBoard(\n",
        "                  log_dir=logdir,\n",
        "                  histogram_freq=1\n",
        "              ),\n",
        "              EarlyStopping(\n",
        "                  monitor='val_top_1_accuracy',\n",
        "                  patience=10,\n",
        "                  restore_best_weights=True,\n",
        "              ),\n",
        "              ModelCheckpoint(\n",
        "                  logdir+'/checkpoint',\n",
        "                  monitor='val_top_1_accuracy',\n",
        "                  save_best_only=True,\n",
        "              ),\n",
        "              TerminateOnNaN(),\n",
        "              cm_callback,\n",
        "          ],\n",
        ")\n"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2023-04-27T13:57:03.714301Z",
          "iopub.execute_input": "2023-04-27T13:57:03.714684Z",
          "iopub.status.idle": "2023-04-27T13:57:45.996478Z",
          "shell.execute_reply.started": "2023-04-27T13:57:03.714652Z",
          "shell.execute_reply": "2023-04-27T13:57:45.994844Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "s5LGZ-WYAneu",
        "outputId": "b05a0142-daac-44c0-9f57-a3a49a239293"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "98/98 [==============================] - ETA: 0s - loss: 1.4304 - top_1_accuracy: 0.6113 - top_5_accuracy: 0.8676"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_top_1_accuracy` which is not available. Available metrics are: loss,top_1_accuracy,top_5_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_top_1_accuracy available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 44s 128ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-3285838106fc>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# convolutional layers from inception V3. We will freeze the bottom N layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# and train the remaining top layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m model.fit(x_train, y_train,\n\u001b[0m\u001b[1;32m     12\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-2b8d43579961>\u001b[0m in \u001b[0;36mlog_confusion_matrix\u001b[0;34m(epoch, logs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0;31m# Calculate the confusion matrix.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m   \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m   \u001b[0;31m# Log the confusion matrix as an image summary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0mfigure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sklearn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_external tensorboard"
      ],
      "metadata": {
        "id": "lWlI-SuLAneu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir ./logs/fit"
      ],
      "metadata": {
        "id": "fqZ39brfAnev"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
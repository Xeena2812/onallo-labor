{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the CIFAR-100 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data(label_mode='fine')\n",
    "\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\levi2\\AppData\\Local\\Temp\\ipykernel_8432\\1897261821.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "False\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.is_gpu_available())\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train / 255 - 0.5) * 2\n",
    "x_test = (x_test / 255 - 0.5) * 2\n",
    "\n",
    "enc = LabelBinarizer()\n",
    "\n",
    "y_train = enc.fit_transform(y_train)\n",
    "y_test = enc.fit_transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_test[0].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception v4 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1, 1, 1024)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"max_pooling2d_26\" (type MaxPooling2D).\n\nNegative dimension size caused by subtracting 3 from 1 for '{{node max_pooling2d_26/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 3, 3, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,1024].\n\nCall arguments received by layer \"max_pooling2d_26\" (type MaxPooling2D):\n  • inputs=tf.Tensor(shape=(None, 1, 1, 1024), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 157\u001b[0m\n\u001b[0;32m    153\u001b[0m     x \u001b[39m=\u001b[39m Concatenate()([branch_0, branch_1, branch_2])\n\u001b[0;32m    154\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n\u001b[1;32m--> 157\u001b[0m model \u001b[39m=\u001b[39m MyInception()\n\u001b[0;32m    159\u001b[0m model\u001b[39m.\u001b[39mcompile()\n\u001b[0;32m    161\u001b[0m model\u001b[39m.\u001b[39msummary()\n",
      "Cell \u001b[1;32mIn[15], line 19\u001b[0m, in \u001b[0;36mMyInception\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m7\u001b[39m):\n\u001b[0;32m     17\u001b[0m     x \u001b[39m=\u001b[39m InceptionB(x)\n\u001b[1;32m---> 19\u001b[0m x \u001b[39m=\u001b[39m ReductionB(x)\n\u001b[0;32m     21\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m):\n\u001b[0;32m     22\u001b[0m     x \u001b[39m=\u001b[39m InceptionC(x)\n",
      "Cell \u001b[1;32mIn[15], line 143\u001b[0m, in \u001b[0;36mReductionB\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mReductionB\u001b[39m(x):\n\u001b[0;32m    142\u001b[0m     \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[1;32m--> 143\u001b[0m     branch_0 \u001b[39m=\u001b[39m MaxPooling2D(pool_size\u001b[39m=\u001b[39;49m(\u001b[39m3\u001b[39;49m, \u001b[39m3\u001b[39;49m), strides\u001b[39m=\u001b[39;49m(\u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m), padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mvalid\u001b[39;49m\u001b[39m'\u001b[39;49m)(x)\n\u001b[0;32m    145\u001b[0m     branch_1 \u001b[39m=\u001b[39m Conv2DBatchNorm(x, \u001b[39m192\u001b[39m, (\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[0;32m    146\u001b[0m     branch_1 \u001b[39m=\u001b[39m Conv2DBatchNorm(branch_1, \u001b[39m192\u001b[39m, (\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m), strides\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m), padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\levi2\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\levi2\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1973\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1970\u001b[0m   c_op \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39mTF_FinishOperation(op_desc)\n\u001b[0;32m   1971\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mInvalidArgumentError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1972\u001b[0m   \u001b[39m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[1;32m-> 1973\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(e\u001b[39m.\u001b[39mmessage)\n\u001b[0;32m   1975\u001b[0m \u001b[39m# Record the current Python stack trace as the creating stacktrace of this\u001b[39;00m\n\u001b[0;32m   1976\u001b[0m \u001b[39m# TF_Operation.\u001b[39;00m\n\u001b[0;32m   1977\u001b[0m \u001b[39mif\u001b[39;00m extract_traceback:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"max_pooling2d_26\" (type MaxPooling2D).\n\nNegative dimension size caused by subtracting 3 from 1 for '{{node max_pooling2d_26/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 3, 3, 1], padding=\"VALID\", strides=[1, 2, 2, 1]](Placeholder)' with input shapes: [?,1,1,1024].\n\nCall arguments received by layer \"max_pooling2d_26\" (type MaxPooling2D):\n  • inputs=tf.Tensor(shape=(None, 1, 1, 1024), dtype=float32)"
     ]
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "from keras.layers import Dense, Conv2D, Input, MaxPooling2D, BatchNormalization, Activation, AveragePooling2D, Dropout, Concatenate\n",
    "#from keras.layers import *\n",
    "from keras import Model\n",
    "\n",
    "def MyInception():\n",
    "    inputs = Input(shape=(32, 32, 3), name='input')\n",
    "\n",
    "    x = Stem(inputs)\n",
    "\n",
    "    for _ in range(4):\n",
    "        x = InceptionA(x)\n",
    "\n",
    "    x = ReductionA(x)\n",
    "\n",
    "    for _ in range(7):\n",
    "        x = InceptionB(x)\n",
    "\n",
    "    x = ReductionB(x)\n",
    "\n",
    "    for _ in range(3):\n",
    "        x = InceptionC(x)\n",
    "\n",
    "    x = AveragePooling2D()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    outputs = Dense(100, activation='softmax', name='output')(x)\n",
    "    model = Model(inputs=inputs, outputs=outputs, name='MyInception')\n",
    "\n",
    "    return model\n",
    "\n",
    "# TODO: Go to Inceptionv2 paper to understand Conv2D_BN and fine tune parameters potentially\n",
    "def Conv2DBatchNorm(x, filters, kernel_size=(3, 3), strides=(1, 1), padding='same'):\n",
    "\n",
    "    x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding)(x)\n",
    "            #    kernel_regularizer=keras.regularizers.l2(0.00004),\n",
    "            #    kernel_initializer=keras.initializers.VarianceScaling(scale=0.2, mode='fan_in', distribution='normal', seed=None)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def Stem(x):\n",
    "    x = Conv2DBatchNorm(x, 32, (3, 3), strides=(2, 2), padding='valid')\n",
    "    x = Conv2DBatchNorm(x, 32, (3, 3), padding='valid')\n",
    "    x = Conv2DBatchNorm(x, 64, (3, 3))\n",
    "\n",
    "    branch_0 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid')(x)\n",
    "    branch_1 = Conv2DBatchNorm(x, 96, (3, 3), strides=(2, 2), padding='valid')\n",
    "\n",
    "    x = Concatenate()([branch_0, branch_1])\n",
    "\n",
    "    branch_0 = Conv2DBatchNorm(x, 64, (1, 1))\n",
    "    branch_0 = Conv2DBatchNorm(branch_0, 96, (3, 3), padding='valid')\n",
    "\n",
    "    branch_1 = Conv2DBatchNorm(x, 64, (1, 1))\n",
    "    branch_1 = Conv2DBatchNorm(branch_1, 64, (7, 1))\n",
    "    branch_1 = Conv2DBatchNorm(branch_1, 64, (1, 7))\n",
    "    branch_1 = Conv2DBatchNorm(branch_1, 96, (3, 3), padding='valid')\n",
    "\n",
    "    x = Concatenate()([branch_0, branch_1])\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def InceptionA(x):\n",
    "    branch_0 = AveragePooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_0 = Conv2DBatchNorm(branch_0, 96, (1, 1))\n",
    "\n",
    "    branch_1 = Conv2DBatchNorm(x, 96, (1, 1))\n",
    "\n",
    "    branch_2 = Conv2DBatchNorm(x, 64, (1, 1))\n",
    "    branch_2 = Conv2DBatchNorm(branch_2, 96, (3, 3))\n",
    "\n",
    "    branch_3 = Conv2DBatchNorm(x, 64, (1, 1))\n",
    "    branch_3 = Conv2DBatchNorm(branch_3, 96, (3, 3))\n",
    "    branch_3 = Conv2DBatchNorm(branch_3, 96, (3, 3))\n",
    "\n",
    "    x = Concatenate()([branch_0, branch_1, branch_2, branch_3])\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def InceptionB(x):\n",
    "    branch_0 = AveragePooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_0 = Conv2DBatchNorm(branch_0, 128, (1, 1))\n",
    "\n",
    "    branch_1 = Conv2DBatchNorm(x, 384, (1, 1))\n",
    "\n",
    "    branch_2 = Conv2DBatchNorm(x, 192, (1, 1))\n",
    "    branch_2 = Conv2DBatchNorm(branch_2, 224, (1, 7))\n",
    "    branch_2 = Conv2DBatchNorm(branch_2, 256, (7, 1))\n",
    "\n",
    "    branch_3 = Conv2DBatchNorm(x, 192, (1, 1))\n",
    "    branch_3 = Conv2DBatchNorm(branch_3, 192, (1, 7))\n",
    "    branch_3 = Conv2DBatchNorm(branch_3, 224, (7, 1))\n",
    "    branch_3 = Conv2DBatchNorm(branch_3, 224, (1, 7))\n",
    "    branch_3 = Conv2DBatchNorm(branch_3, 256, (7, 1))\n",
    "\n",
    "    x = Concatenate()([branch_0, branch_1, branch_2, branch_3])\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def InceptionC(x):\n",
    "    branch_0 = AveragePooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_0 = Conv2DBatchNorm(branch_0, 256, (1, 1))\n",
    "\n",
    "    branch_1 = Conv2DBatchNorm(x, 256, (1, 1))\n",
    "\n",
    "    branch_2 = Conv2DBatchNorm(x, 384, (1, 1))\n",
    "    branch_2_0 = Conv2DBatchNorm(branch_2, 256, (1, 3))\n",
    "    branch_2_1 = Conv2DBatchNorm(branch_2, 256, (3, 1))\n",
    "\n",
    "    branch_3 = Conv2DBatchNorm(x, 384, (1, 1))\n",
    "    branch_3 = Conv2DBatchNorm(branch_3, 448, (1, 3))\n",
    "    branch_3 = Conv2DBatchNorm(branch_3, 512, (3, 1))\n",
    "    branch_3_0 = Conv2DBatchNorm(branch_3, 256, (3, 1))\n",
    "    branch_3_1 = Conv2DBatchNorm(branch_3, 256, (1, 3))\n",
    "\n",
    "    x = Concatenate()([branch_0, branch_1, branch_2_0, branch_2_1, branch_3_0, branch_3_1])\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def ReductionA(x):\n",
    "    branch_0 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid')(x)\n",
    "\n",
    "    branch_1 = Conv2DBatchNorm(x, 384, (3, 3), strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_2 = Conv2DBatchNorm(x, 192, (1, 1))\n",
    "    branch_2 = Conv2DBatchNorm(branch_2, 224, (3, 3))\n",
    "    branch_2 = Conv2DBatchNorm(branch_2, 256, (3, 3), strides=(2, 2), padding='valid')\n",
    "\n",
    "    x = Concatenate()([branch_0, branch_1, branch_2])\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def ReductionB(x):\n",
    "    print(x.shape)\n",
    "    branch_0 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid')(x)\n",
    "\n",
    "    branch_1 = Conv2DBatchNorm(x, 192, (1, 1))\n",
    "    branch_1 = Conv2DBatchNorm(branch_1, 192, (3, 3), strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_2 = Conv2DBatchNorm(x, 256, (1, 1))\n",
    "    branch_2 = Conv2DBatchNorm(branch_2, 256, (1, 7))\n",
    "    branch_2 = Conv2DBatchNorm(branch_2, 320, (7, 1))\n",
    "    branch_2 = Conv2DBatchNorm(branch_2, 320, (3, 3), strides=(2, 2), padding='valid')\n",
    "\n",
    "    x = Concatenate()([branch_0, branch_1, branch_2])\n",
    "    return x\n",
    "\n",
    "\n",
    "model = MyInception()\n",
    "\n",
    "model.compile()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 1, 1, 96), (None, 4, 4, 96), (None, 4, 4, 96), (None, 4, 4, 96)]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m MyInception()\n\u001b[0;32m      3\u001b[0m model\u001b[39m.\u001b[39mcompile()\n\u001b[0;32m      5\u001b[0m model\u001b[39m.\u001b[39msummary()\n",
      "Cell \u001b[1;32mIn[7], line 12\u001b[0m, in \u001b[0;36mMyInception\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m x \u001b[39m=\u001b[39m Stem(inputs)\n\u001b[0;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m4\u001b[39m):\n\u001b[1;32m---> 12\u001b[0m     x \u001b[39m=\u001b[39m InceptionA(x)\n\u001b[0;32m     14\u001b[0m x \u001b[39m=\u001b[39m ReductionA(x)\n\u001b[0;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m7\u001b[39m):\n",
      "Cell \u001b[1;32mIn[7], line 80\u001b[0m, in \u001b[0;36mInceptionA\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     77\u001b[0m branch_3 \u001b[39m=\u001b[39m Conv2DBatchNorm(branch_3, \u001b[39m96\u001b[39m, (\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m))\n\u001b[0;32m     78\u001b[0m branch_3 \u001b[39m=\u001b[39m Conv2DBatchNorm(branch_3, \u001b[39m96\u001b[39m, (\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m))\n\u001b[1;32m---> 80\u001b[0m x \u001b[39m=\u001b[39m Concatenate()([branch_0, branch_1, branch_2, branch_3])\n\u001b[0;32m     82\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\levi2\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\levi2\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\layers\\merging\\concatenate.py:131\u001b[0m, in \u001b[0;36mConcatenate.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    125\u001b[0m unique_dims \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(\n\u001b[0;32m    126\u001b[0m     shape[axis]\n\u001b[0;32m    127\u001b[0m     \u001b[39mfor\u001b[39;00m shape \u001b[39min\u001b[39;00m shape_set\n\u001b[0;32m    128\u001b[0m     \u001b[39mif\u001b[39;00m shape[axis] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    129\u001b[0m )\n\u001b[0;32m    130\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(unique_dims) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 131\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err_msg)\n",
      "\u001b[1;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 1, 1, 96), (None, 4, 4, 96), (None, 4, 4, 96), (None, 4, 4, 96)]"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a5fa9285215e4b0b41af508f79a138b9553c6fbd1ae80ad44751154a42b4e6d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

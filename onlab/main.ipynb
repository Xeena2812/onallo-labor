{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Xeena2812/onallo-labor/blob/fit-to-cifar-inceptionv4/onlab/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6aYgnzA2I9d"
      },
      "source": [
        "## Importing the CIFAR-100 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-zZzqr062I9f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euNbEV-D2I9g",
        "outputId": "3805d172-b047-40b3-f28c-4b614ed3ad21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 2s 0us/step\n",
            "(50000, 32, 32, 3) (50000, 1)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data(label_mode='fine')\n",
        "\n",
        "print(x_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "098ezWUT2I9h",
        "outputId": "5452cd92-ef6b-471f-da47-d3e3fa23c236"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "print(tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dp9X6eNL2I9h"
      },
      "outputs": [],
      "source": [
        "x_train = (x_train / 255 - 0.5) * 2\n",
        "x_test = (x_test / 255 - 0.5) * 2\n",
        "\n",
        "enc = LabelBinarizer()\n",
        "\n",
        "y_train = enc.fit_transform(y_train)\n",
        "y_test = enc.fit_transform(y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ms4zegUs2I9i",
        "outputId": "97416265-ef05-4d75-c8d4-6917c4a4041d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 32, 3)\n",
            "(100,)\n"
          ]
        }
      ],
      "source": [
        "print(x_test[0].shape)\n",
        "print(y_test[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY8Dp8gn2I9i"
      },
      "source": [
        "## Inception v4 Implementation\n",
        "\n",
        "The CIFAR100 dataset is composed of 32x32 pixel images as oppopsed to the 299x299 pixel images of the Imagenet network for which the Inceptionv4 network was originally comstructed. There a significant downsizing of the network is necessary to accomodate the 10x size difference.\n",
        "\n",
        "Inception blocks are used to create feature maps, and reduction blocks are used to downsize the filter size for teh inception blocks\n",
        "Intuitions:\n",
        "1. Put 5x5 convolutions in stem to downsize image to smaller size, and expand filter space for the Inception-A blocks.\n",
        "2. First inception blocks TRANSFORM the feature map (with 1x1 convolutions) while KEEPING the same image and filter size.\n",
        "3. Reduction-A blocks further reduce the image size and expand filter space for Inception-B blocks.\n",
        "4. Inception-B blocks further transform the feature map.\n",
        "5. Probably not neccessary, but if it is add Reduction-B blocks\n",
        "6. A final AveragePooling layer reduces  \n",
        "\n",
        "1. Drop the reduction blocks as the image is already small adn there is no need to reduce image size (probably only dimension reduction is needed)\n",
        "   1. this probably won't work as different size feature extraction is necessary\n",
        "2. Reduce the number of Conv2DBatchNorm layers in each block (Inception, Reduction, Stem) in order not to decrease the image size down to one so quickly\n",
        "3. Change all filter numbers to half.\n",
        "\n",
        "10. Take design principles outlaid in the v3 paper into account"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXTg2ZfN2I9j",
        "outputId": "57b37fa8-fc6f-4371-dfd3-cf8f70edcceb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pre-stem size: (None, 32, 32, 3)\n",
            "post-stem size: (None, 13, 13, 192)\n",
            "pre-A size: (None, 13, 13, 192)\n",
            "post-A size: (None, 13, 13, 192)\n",
            "pre-A size: (None, 13, 13, 192)\n",
            "post-A size: (None, 13, 13, 192)\n",
            "pre-RedA size: (None, 13, 13, 192)\n",
            "post-RedA size: (None, 6, 6, 512)\n",
            "pre-B size: (None, 6, 6, 512)\n",
            "post-B size: (None, 6, 6, 512)\n",
            "pre-B size: (None, 6, 6, 512)\n",
            "post-B size: (None, 6, 6, 512)\n",
            "pre-B size: (None, 6, 6, 512)\n",
            "post-B size: (None, 6, 6, 512)\n",
            "pre-RedB size: (None, 6, 6, 512)\n",
            "post-RedB size: (None, 3, 3, 1024)\n",
            "pre-C size: (None, 3, 3, 1024)\n",
            "post-C size: (None, 3, 3, 768)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6319316"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "#import tensorflow as tf\n",
        "from keras.layers import Dense, Conv2D, Input, MaxPooling2D, BatchNormalization, Activation, AveragePooling2D, Dropout, Concatenate, Flatten\n",
        "#from keras.layers import *\n",
        "from keras import Model\n",
        "\n",
        "\n",
        "# TODO: Go to Inceptionv2 paper to understand Conv2D_BN and fine tune parameters potentially\n",
        "def Conv2DBatchNorm(x, filters, kernel_size=(3, 3), strides=(1, 1), padding='same'):\n",
        "\n",
        "    x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "def Stem(x):\n",
        "    print(\"pre-stem size:\", x.shape)\n",
        "\n",
        "    x = Conv2DBatchNorm(x, 16, (5, 5))\n",
        "    x = Conv2DBatchNorm(x, 32, (3, 3))\n",
        "\n",
        "    branch_0 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid')(x)\n",
        "    branch_1 = Conv2DBatchNorm(x, 48, (3, 3), strides=(2, 2), padding='valid')\n",
        "\n",
        "    x = Concatenate()([branch_0, branch_1])\n",
        "    \n",
        "    branch_0 = Conv2DBatchNorm(x, 32, (1, 1))\n",
        "    branch_0 = Conv2DBatchNorm(branch_0, 48, (3, 3), padding='valid')\n",
        "\n",
        "    branch_1 = Conv2DBatchNorm(x, 32, (1, 1))\n",
        "    branch_1 = Conv2DBatchNorm(branch_1, 32, (1, 7))\n",
        "    branch_1 = Conv2DBatchNorm(branch_1, 32, (7, 1))\n",
        "    branch_1 = Conv2DBatchNorm(branch_1, 48, (3, 3), padding='valid')\n",
        "\n",
        "    x = Concatenate()([branch_0, branch_1])\n",
        "    \n",
        "    branch_0 = Conv2DBatchNorm(x, 96, (3, 3))\n",
        "\n",
        "    # Here another reduction by half should occur according too inceptionv4, but it's too big a reduction so it's left off.\n",
        "    branch_1 = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
        "\n",
        "    x = Concatenate()([branch_0, branch_1])\n",
        "\n",
        "    print(\"post-stem size:\", x.shape)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def InceptionA(x):\n",
        "    print(\"pre-A size:\", x.shape)\n",
        "\n",
        "    branch_0 = AveragePooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch_0 = Conv2DBatchNorm(branch_0, 48, (1, 1))\n",
        "\n",
        "    branch_1 = Conv2DBatchNorm(x, 48, (1, 1))\n",
        "\n",
        "    branch_2 = Conv2DBatchNorm(x, 32, (1, 1))\n",
        "    branch_2 = Conv2DBatchNorm(branch_2, 48, (3, 3))\n",
        "\n",
        "    branch_3 = Conv2DBatchNorm(x, 32, (1, 1))\n",
        "    branch_3 = Conv2DBatchNorm(branch_3, 48, (3, 3))\n",
        "    branch_3 = Conv2DBatchNorm(branch_3, 48, (3, 3))\n",
        "\n",
        "    x = Concatenate()([branch_0, branch_1, branch_2, branch_3])\n",
        "    print(\"post-A size:\", x.shape)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def InceptionB(x):\n",
        "    print(\"pre-B size:\", x.shape)\n",
        "\n",
        "    branch_0 = AveragePooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch_0 = Conv2DBatchNorm(branch_0, 64, (1, 1))\n",
        "\n",
        "    branch_1 = Conv2DBatchNorm(x, 192, (1, 1))\n",
        "\n",
        "    branch_2 = Conv2DBatchNorm(x, 96, (1, 1))\n",
        "    branch_2 = Conv2DBatchNorm(branch_2, 112, (1, 7))\n",
        "    branch_2 = Conv2DBatchNorm(branch_2, 128, (7, 1))\n",
        "\n",
        "    branch_3 = Conv2DBatchNorm(x, 96, (1, 1))\n",
        "    branch_3 = Conv2DBatchNorm(branch_3, 96, (1, 7))\n",
        "    branch_3 = Conv2DBatchNorm(branch_3, 112, (7, 1))\n",
        "    branch_3 = Conv2DBatchNorm(branch_3, 112, (1, 7))\n",
        "    branch_3 = Conv2DBatchNorm(branch_3, 128, (7, 1))\n",
        "\n",
        "    x = Concatenate()([branch_0, branch_1, branch_2, branch_3])\n",
        "    print(\"post-B size:\", x.shape)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def InceptionC(x):\n",
        "    print(\"pre-C size:\", x.shape)\n",
        "\n",
        "    branch_0 = AveragePooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch_0 = Conv2DBatchNorm(branch_0, 128, (1, 1))\n",
        "\n",
        "    branch_1 = Conv2DBatchNorm(x, 128, (1, 1))\n",
        "\n",
        "    branch_2 = Conv2DBatchNorm(x, 192, (1, 1))\n",
        "    branch_2_0 = Conv2DBatchNorm(branch_2, 128, (1, 3))\n",
        "    branch_2_1 = Conv2DBatchNorm(branch_2, 128, (3, 1))\n",
        "\n",
        "    branch_3 = Conv2DBatchNorm(x, 192, (1, 1))\n",
        "    branch_3 = Conv2DBatchNorm(branch_3, 224, (1, 3))\n",
        "    branch_3 = Conv2DBatchNorm(branch_3, 256, (3, 1))\n",
        "    branch_3_0 = Conv2DBatchNorm(branch_3, 128, (3, 1))\n",
        "    branch_3_1 = Conv2DBatchNorm(branch_3, 128, (1, 3))\n",
        "\n",
        "    x = Concatenate()([branch_0, branch_1, branch_2_0, branch_2_1, branch_3_0, branch_3_1])\n",
        "    print(\"post-C size:\", x.shape)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def ReductionA(x):\n",
        "    print(\"pre-RedA size:\", x.shape)\n",
        "\n",
        "    branch_0 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid')(x)\n",
        "\n",
        "    branch_1 = Conv2DBatchNorm(x, 192, (3, 3), strides=(2, 2), padding='valid')\n",
        "\n",
        "    branch_2 = Conv2DBatchNorm(x, 96, (1, 1))\n",
        "    branch_2 = Conv2DBatchNorm(branch_2, 112, (3, 3))\n",
        "    branch_2 = Conv2DBatchNorm(branch_2, 128, (3, 3), strides=(2, 2), padding='valid')\n",
        "\n",
        "    x = Concatenate()([branch_0, branch_1, branch_2])\n",
        "    print(\"post-RedA size:\", x.shape)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def ReductionB(x):\n",
        "    print(\"pre-RedB size:\", x.shape)\n",
        "\n",
        "    branch_0 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(x)\n",
        "\n",
        "    branch_1 = Conv2DBatchNorm(x, 192, (1, 1))\n",
        "    branch_1 = Conv2DBatchNorm(branch_1, 192, (2, 2), strides=(2, 2), padding='valid')\n",
        "\n",
        "    branch_2 = Conv2DBatchNorm(x, 256, (1, 1))\n",
        "    branch_2 = Conv2DBatchNorm(branch_2, 256, (1, 7))\n",
        "    branch_2 = Conv2DBatchNorm(branch_2, 320, (7, 1))\n",
        "    branch_2 = Conv2DBatchNorm(branch_2, 320, (2, 2), strides=(2, 2), padding='valid')\n",
        "\n",
        "    x = Concatenate()([branch_0, branch_1, branch_2])\n",
        "    print(\"post-RedB size:\", x.shape)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def MyInception():\n",
        "    inputs = Input(shape=(32, 32, 3), name='input')\n",
        "\n",
        "    x = Stem(inputs)\n",
        "\n",
        "    for _ in range(2):\n",
        "        x = InceptionA(x)\n",
        "\n",
        "    x = ReductionA(x)\n",
        "\n",
        "    for _ in range(3):\n",
        "        x = InceptionB(x)\n",
        "\n",
        "    x = ReductionB(x)\n",
        "\n",
        "    #for _ in range(3):\n",
        "    x = InceptionC(x)\n",
        "\n",
        "    x = AveragePooling2D()(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    outputs = Dense(100, activation='softmax', name='output')(x)\n",
        "    model = Model(inputs=inputs, outputs=outputs, name='MyInception')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model = MyInception()\n",
        "\n",
        "model.compile()\n",
        "\n",
        "model.count_params()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes:\n",
        "\n",
        "The Stem Reduces image size from 299 to 35 in the original Inceptionv4 architecture which is a 1/10 scale. That is too large of a downscale and we can't afford that with a 32 by 32 image. That's why my stem only reduces image 1/3. I've also reduced all teh filter numbers to half their original number, because presumably for a smaller mage a smaller repsresentation will be sufficient\n",
        "\n",
        "Questions:\n",
        "What metrics to use\n",
        "What to log\n",
        "How many blocks to use"
      ],
      "metadata": {
        "id": "WuTwD5YL54Cr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f491y2S52I9k"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "a5fa9285215e4b0b41af508f79a138b9553c6fbd1ae80ad44751154a42b4e6d9"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
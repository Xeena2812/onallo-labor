{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Xeena2812/onallo-labor/blob/fit-to-cifar-inceptionv4/onlab/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6aYgnzA2I9d"
      },
      "source": [
        "## Importing the CIFAR-100 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-zZzqr062I9f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euNbEV-D2I9g",
        "outputId": "3805d172-b047-40b3-f28c-4b614ed3ad21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169001437/169001437 [==============================] - 2s 0us/step\n",
            "(50000, 32, 32, 3) (50000, 1)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data(label_mode='fine')\n",
        "\n",
        "print(x_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "098ezWUT2I9h",
        "outputId": "5452cd92-ef6b-471f-da47-d3e3fa23c236"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "print(tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dp9X6eNL2I9h"
      },
      "outputs": [],
      "source": [
        "x_train = (x_train / 255 - 0.5) * 2\n",
        "x_test = (x_test / 255 - 0.5) * 2\n",
        "\n",
        "enc = LabelBinarizer()\n",
        "\n",
        "y_train = enc.fit_transform(y_train)\n",
        "y_test = enc.fit_transform(y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ms4zegUs2I9i",
        "outputId": "97416265-ef05-4d75-c8d4-6917c4a4041d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 32, 3)\n",
            "(100,)\n"
          ]
        }
      ],
      "source": [
        "print(x_test[0].shape)\n",
        "print(y_test[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY8Dp8gn2I9i"
      },
      "source": [
        "## Inception v4 Implementation\n",
        "\n",
        "The CIFAR100 dataset is composed of 32x32 pixel images as oppopsed to the 299x299 pixel images of the Imagenet network for which the Inceptionv4 network was originally comstructed. There a significant downsizing of the network is necessary to accomodate the 10x size difference.\n",
        "\n",
        "Inception blocks are used to create feature maps, and reduction blocks are used to downsize the filter size for teh inception blocks\n",
        "Intuitions:\n",
        "1. Put 5x5 convolutions in stem to downsize image to smaller size, and expand filter space for the Inception-A blocks.\n",
        "2. First inception blocks TRANSFORM the feature map (with 1x1 convolutions) while KEEPING the same image and filter size.\n",
        "3. Reduction-A blocks further reduce the image size and expand filter space for Inception-B blocks.\n",
        "4. Inception-B blocks further transform the feature map.\n",
        "5. Probably not neccessary, but if it is add Reduction-B blocks\n",
        "6. A final AveragePooling layer reduces  \n",
        "\n",
        "1. Drop the reduction blocks as the image is already small adn there is no need to reduce image size (probably only dimension reduction is needed)\n",
        "   1. this probably won't work as different size feature extraction is necessary\n",
        "2. Reduce the number of Conv2DBatchNorm layers in each block (Inception, Reduction, Stem) in order not to decrease the image size down to one so quickly\n",
        "3. Change all filter numbers to half.\n",
        "\n",
        "10. Take design principles outlaid in the v3 paper into account"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXTg2ZfN2I9j",
        "outputId": "8c53c73c-25bd-4744-944c-86910ac9ad8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pre-stem size: (None, 32, 32, 3)\n",
            "post-stem size: (None, 13, 13, 192)\n",
            "pre-A size: (None, 13, 13, 192)\n",
            "post-A size: (None, 13, 13, 192)\n",
            "Model: \"MyInception\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input (InputLayer)             [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_100 (Conv2D)            (None, 32, 32, 16)   1216        ['input[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_100 (Batch  (None, 32, 32, 16)  64          ['conv2d_100[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_100 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_100[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_101 (Conv2D)            (None, 32, 32, 32)   4640        ['activation_100[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_101 (Batch  (None, 32, 32, 32)  128         ['conv2d_101[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_101 (Activation)    (None, 32, 32, 32)   0           ['batch_normalization_101[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_102 (Conv2D)            (None, 15, 15, 48)   13872       ['activation_101[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_102 (Batch  (None, 15, 15, 48)  192         ['conv2d_102[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " max_pooling2d_22 (MaxPooling2D  (None, 15, 15, 32)  0           ['activation_101[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " activation_102 (Activation)    (None, 15, 15, 48)   0           ['batch_normalization_102[0][0]']\n",
            "                                                                                                  \n",
            " concatenate_33 (Concatenate)   (None, 15, 15, 80)   0           ['max_pooling2d_22[0][0]',       \n",
            "                                                                  'activation_102[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_105 (Conv2D)            (None, 15, 15, 32)   2592        ['concatenate_33[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_105 (Batch  (None, 15, 15, 32)  128         ['conv2d_105[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_105 (Activation)    (None, 15, 15, 32)   0           ['batch_normalization_105[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_106 (Conv2D)            (None, 15, 15, 32)   7200        ['activation_105[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_106 (Batch  (None, 15, 15, 32)  128         ['conv2d_106[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_106 (Activation)    (None, 15, 15, 32)   0           ['batch_normalization_106[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_103 (Conv2D)            (None, 15, 15, 32)   2592        ['concatenate_33[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_107 (Conv2D)            (None, 15, 15, 32)   7200        ['activation_106[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_103 (Batch  (None, 15, 15, 32)  128         ['conv2d_103[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_107 (Batch  (None, 15, 15, 32)  128         ['conv2d_107[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_103 (Activation)    (None, 15, 15, 32)   0           ['batch_normalization_103[0][0]']\n",
            "                                                                                                  \n",
            " activation_107 (Activation)    (None, 15, 15, 32)   0           ['batch_normalization_107[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_104 (Conv2D)            (None, 13, 13, 48)   13872       ['activation_103[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_108 (Conv2D)            (None, 13, 13, 48)   13872       ['activation_107[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_104 (Batch  (None, 13, 13, 48)  192         ['conv2d_104[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_108 (Batch  (None, 13, 13, 48)  192         ['conv2d_108[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_104 (Activation)    (None, 13, 13, 48)   0           ['batch_normalization_104[0][0]']\n",
            "                                                                                                  \n",
            " activation_108 (Activation)    (None, 13, 13, 48)   0           ['batch_normalization_108[0][0]']\n",
            "                                                                                                  \n",
            " concatenate_34 (Concatenate)   (None, 13, 13, 96)   0           ['activation_104[0][0]',         \n",
            "                                                                  'activation_108[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_109 (Conv2D)            (None, 13, 13, 96)   83040       ['concatenate_34[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_109 (Batch  (None, 13, 13, 96)  384         ['conv2d_109[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_109 (Activation)    (None, 13, 13, 96)   0           ['batch_normalization_109[0][0]']\n",
            "                                                                                                  \n",
            " max_pooling2d_23 (MaxPooling2D  (None, 13, 13, 96)  0           ['concatenate_34[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " concatenate_35 (Concatenate)   (None, 13, 13, 192)  0           ['activation_109[0][0]',         \n",
            "                                                                  'max_pooling2d_23[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_114 (Conv2D)            (None, 13, 13, 32)   6176        ['concatenate_35[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_114 (Batch  (None, 13, 13, 32)  128         ['conv2d_114[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_114 (Activation)    (None, 13, 13, 32)   0           ['batch_normalization_114[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_112 (Conv2D)            (None, 13, 13, 32)   6176        ['concatenate_35[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_115 (Conv2D)            (None, 13, 13, 48)   13872       ['activation_114[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_112 (Batch  (None, 13, 13, 32)  128         ['conv2d_112[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_115 (Batch  (None, 13, 13, 48)  192         ['conv2d_115[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 13, 13, 192)  0          ['concatenate_35[0][0]']         \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " activation_112 (Activation)    (None, 13, 13, 32)   0           ['batch_normalization_112[0][0]']\n",
            "                                                                                                  \n",
            " activation_115 (Activation)    (None, 13, 13, 48)   0           ['batch_normalization_115[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_110 (Conv2D)            (None, 13, 13, 48)   9264        ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_111 (Conv2D)            (None, 13, 13, 48)   9264        ['concatenate_35[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_113 (Conv2D)            (None, 13, 13, 48)   13872       ['activation_112[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_116 (Conv2D)            (None, 13, 13, 48)   20784       ['activation_115[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_110 (Batch  (None, 13, 13, 48)  192         ['conv2d_110[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_111 (Batch  (None, 13, 13, 48)  192         ['conv2d_111[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_113 (Batch  (None, 13, 13, 48)  192         ['conv2d_113[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " batch_normalization_116 (Batch  (None, 13, 13, 48)  192         ['conv2d_116[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_110 (Activation)    (None, 13, 13, 48)   0           ['batch_normalization_110[0][0]']\n",
            "                                                                                                  \n",
            " activation_111 (Activation)    (None, 13, 13, 48)   0           ['batch_normalization_111[0][0]']\n",
            "                                                                                                  \n",
            " activation_113 (Activation)    (None, 13, 13, 48)   0           ['batch_normalization_113[0][0]']\n",
            "                                                                                                  \n",
            " activation_116 (Activation)    (None, 13, 13, 48)   0           ['batch_normalization_116[0][0]']\n",
            "                                                                                                  \n",
            " concatenate_36 (Concatenate)   (None, 13, 13, 192)  0           ['activation_110[0][0]',         \n",
            "                                                                  'activation_111[0][0]',         \n",
            "                                                                  'activation_113[0][0]',         \n",
            "                                                                  'activation_116[0][0]']         \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (AveragePo  (None, 6, 6, 192)   0           ['concatenate_36[0][0]']         \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 6, 6, 192)    0           ['average_pooling2d_5[0][0]']    \n",
            "                                                                                                  \n",
            " flatten_4 (Flatten)            (None, 6912)         0           ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " output (Dense)                 (None, 100)          691300      ['flatten_4[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 923,684\n",
            "Trainable params: 922,244\n",
            "Non-trainable params: 1,440\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#import tensorflow as tf\n",
        "from keras.layers import Dense, Conv2D, Input, MaxPooling2D, BatchNormalization, Activation, AveragePooling2D, Dropout, Concatenate, Flatten\n",
        "#from keras.layers import *\n",
        "from keras import Model\n",
        "\n",
        "\n",
        "# TODO: Go to Inceptionv2 paper to understand Conv2D_BN and fine tune parameters potentially\n",
        "def Conv2DBatchNorm(x, filters, kernel_size=(3, 3), strides=(1, 1), padding='same'):\n",
        "\n",
        "    x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "def Stem(x):\n",
        "    print(\"pre-stem size:\", x.shape)\n",
        "\n",
        "    x = Conv2DBatchNorm(x, 16, (5, 5))\n",
        "    x = Conv2DBatchNorm(x, 32, (3, 3))\n",
        "\n",
        "    branch_0 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid')(x)\n",
        "    branch_1 = Conv2DBatchNorm(x, 48, (3, 3), strides=(2, 2), padding='valid')\n",
        "\n",
        "    x = Concatenate()([branch_0, branch_1])\n",
        "    \n",
        "    branch_0 = Conv2DBatchNorm(x, 32, (1, 1))\n",
        "    branch_0 = Conv2DBatchNorm(branch_0, 48, (3, 3), padding='valid')\n",
        "\n",
        "    branch_1 = Conv2DBatchNorm(x, 32, (1, 1))\n",
        "    branch_1 = Conv2DBatchNorm(branch_1, 32, (1, 7))\n",
        "    branch_1 = Conv2DBatchNorm(branch_1, 32, (7, 1))\n",
        "    branch_1 = Conv2DBatchNorm(branch_1, 48, (3, 3), padding='valid')\n",
        "\n",
        "    x = Concatenate()([branch_0, branch_1])\n",
        "    \n",
        "    branch_0 = Conv2DBatchNorm(x, 96, (3, 3))\n",
        "\n",
        "    # Here another reduction by half should occur according too inceptionv4, but it's too big a reduction so it's left off.\n",
        "    branch_1 = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
        "\n",
        "    x = Concatenate()([branch_0, branch_1])\n",
        "\n",
        "    print(\"post-stem size:\", x.shape)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def InceptionA(x):\n",
        "    print(\"pre-A size:\", x.shape)\n",
        "\n",
        "    branch_0 = AveragePooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch_0 = Conv2DBatchNorm(branch_0, 48, (1, 1))\n",
        "\n",
        "    branch_1 = Conv2DBatchNorm(x, 48, (1, 1))\n",
        "\n",
        "    branch_2 = Conv2DBatchNorm(x, 32, (1, 1))\n",
        "    branch_2 = Conv2DBatchNorm(branch_2, 48, (3, 3))\n",
        "\n",
        "    branch_3 = Conv2DBatchNorm(x, 32, (1, 1))\n",
        "    branch_3 = Conv2DBatchNorm(branch_3, 48, (3, 3))\n",
        "    branch_3 = Conv2DBatchNorm(branch_3, 48, (3, 3))\n",
        "\n",
        "    x = Concatenate()([branch_0, branch_1, branch_2, branch_3])\n",
        "    print(\"post-A size:\", x.shape)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def InceptionB(x):\n",
        "    print(\"pre-B size:\", x.shape)\n",
        "\n",
        "    branch_0 = AveragePooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch_0 = Conv2DBatchNorm(branch_0, 64, (1, 1))\n",
        "\n",
        "    branch_1 = Conv2DBatchNorm(x, 192, (1, 1))\n",
        "\n",
        "    branch_2 = Conv2DBatchNorm(x, 96, (1, 1))\n",
        "    branch_2 = Conv2DBatchNorm(branch_2, 112, (1, 7))\n",
        "    branch_2 = Conv2DBatchNorm(branch_2, 128, (7, 1))\n",
        "\n",
        "    branch_3 = Conv2DBatchNorm(x, 96, (1, 1))\n",
        "    branch_3 = Conv2DBatchNorm(branch_3, 96, (1, 7))\n",
        "    branch_3 = Conv2DBatchNorm(branch_3, 112, (7, 1))\n",
        "    branch_3 = Conv2DBatchNorm(branch_3, 112, (1, 7))\n",
        "    branch_3 = Conv2DBatchNorm(branch_3, 128, (7, 1))\n",
        "\n",
        "    x = Concatenate()([branch_0, branch_1, branch_2, branch_3])\n",
        "    print(\"post-B size:\", x.shape)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def InceptionC(x):\n",
        "    print(\"pre-C size:\", x.shape)\n",
        "\n",
        "    branch_0 = AveragePooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
        "    branch_0 = Conv2DBatchNorm(branch_0, 128, (1, 1))\n",
        "\n",
        "    branch_1 = Conv2DBatchNorm(x, 128, (1, 1))\n",
        "\n",
        "    branch_2 = Conv2DBatchNorm(x, 192, (1, 1))\n",
        "    branch_2_0 = Conv2DBatchNorm(branch_2, 128, (1, 3))\n",
        "    branch_2_1 = Conv2DBatchNorm(branch_2, 128, (3, 1))\n",
        "\n",
        "    branch_3 = Conv2DBatchNorm(x, 192, (1, 1))\n",
        "    branch_3 = Conv2DBatchNorm(branch_3, 224, (1, 3))\n",
        "    branch_3 = Conv2DBatchNorm(branch_3, 256, (3, 1))\n",
        "    branch_3_0 = Conv2DBatchNorm(branch_3, 128, (3, 1))\n",
        "    branch_3_1 = Conv2DBatchNorm(branch_3, 128, (1, 3))\n",
        "\n",
        "    x = Concatenate()([branch_0, branch_1, branch_2_0, branch_2_1, branch_3_0, branch_3_1])\n",
        "    print(\"post-C size:\", x.shape)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def ReductionA(x):\n",
        "    print(\"pre-RedA size:\", x.shape)\n",
        "\n",
        "    branch_0 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid')(x)\n",
        "\n",
        "    branch_1 = Conv2DBatchNorm(x, 192, (3, 3), strides=(2, 2), padding='valid')\n",
        "\n",
        "    branch_2 = Conv2DBatchNorm(x, 96, (1, 1))\n",
        "    branch_2 = Conv2DBatchNorm(branch_2, 112, (3, 3))\n",
        "    branch_2 = Conv2DBatchNorm(branch_2, 128, (3, 3), strides=(2, 2), padding='valid')\n",
        "\n",
        "    x = Concatenate()([branch_0, branch_1, branch_2])\n",
        "    print(\"post-RedA size:\", x.shape)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def ReductionB(x):\n",
        "    print(\"pre-RedB size:\", x.shape)\n",
        "\n",
        "    branch_0 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid')(x)\n",
        "\n",
        "    branch_1 = Conv2DBatchNorm(x, 192, (1, 1))\n",
        "    branch_1 = Conv2DBatchNorm(branch_1, 192, (3, 3), strides=(2, 2), padding='valid')\n",
        "\n",
        "    branch_2 = Conv2DBatchNorm(x, 256, (1, 1))\n",
        "    branch_2 = Conv2DBatchNorm(branch_2, 256, (1, 7))\n",
        "    branch_2 = Conv2DBatchNorm(branch_2, 320, (7, 1))\n",
        "    branch_2 = Conv2DBatchNorm(branch_2, 320, (3, 3), strides=(2, 2), padding='valid')\n",
        "\n",
        "    x = Concatenate()([branch_0, branch_1, branch_2])\n",
        "    print(\"post-RedB size:\", x.shape)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def MyInception():\n",
        "    inputs = Input(shape=(32, 32, 3), name='input')\n",
        "\n",
        "    x = Stem(inputs)\n",
        "\n",
        "    for _ in range(2):\n",
        "        x = InceptionA(x)\n",
        "\n",
        "    # x = ReductionA(x)\n",
        "\n",
        "    for _ in range(3):\n",
        "        x = InceptionB(x)\n",
        "\n",
        "    # x = ReductionB(x)\n",
        "\n",
        "    #for _ in range(3):\n",
        "    x = InceptionC(x)\n",
        "\n",
        "    x = AveragePooling2D()(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    outputs = Dense(100, activation='softmax', name='output')(x)\n",
        "    model = Model(inputs=inputs, outputs=outputs, name='MyInception')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model = MyInception()\n",
        "\n",
        "model.compile()\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notes:\n",
        "\n",
        "The Stem Reduces image size from 299 to 35 in the original Inceptionv4 architecture which is a 1/10 scale. That is too large of a downscale and we can't afford that with a 32 by 32 image. That's why my stem only reduces image 1/3. I've also reduced all teh filter numbers to half their original number, because presumably for a smaller mage a smaller repsresentation will be sufficient\n",
        "\n",
        "Questions:\n",
        "What metrics to use\n",
        "What to log\n",
        "How many blocks to use"
      ],
      "metadata": {
        "id": "WuTwD5YL54Cr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f491y2S52I9k"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "a5fa9285215e4b0b41af508f79a138b9553c6fbd1ae80ad44751154a42b4e6d9"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
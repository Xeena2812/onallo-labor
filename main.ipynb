{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Importing the CIFAR-100 dataset","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\n\n(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data(label_mode='fine')\n\nprint(x_train.shape, y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-23T15:12:59.772486Z","iopub.execute_input":"2023-04-23T15:12:59.773139Z","iopub.status.idle":"2023-04-23T15:13:18.305314Z","shell.execute_reply.started":"2023-04-23T15:12:59.773091Z","shell.execute_reply":"2023-04-23T15:13:18.303961Z"},"scrolled":true,"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n169001437/169001437 [==============================] - 6s 0us/step\n(50000, 32, 32, 3) (50000, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(tf.config.list_physical_devices('GPU'))","metadata":{"execution":{"iopub.status.busy":"2023-04-23T15:00:39.565964Z","iopub.execute_input":"2023-04-23T15:00:39.566895Z","iopub.status.idle":"2023-04-23T15:00:39.580431Z","shell.execute_reply.started":"2023-04-23T15:00:39.566843Z","shell.execute_reply":"2023-04-23T15:00:39.578824Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"[]\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.applications.inception_v3 import preprocess_input\nfrom tensorflow.data import Dataset\nfrom keras.layers import Resizing, Rescaling\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\n\nprint(x_train.shape)\n#print(x_valid.shape)\nprint(x_test.shape)\n\nx_train = np.moveaxis(x_train, -1, 1)\nx_valid = np.moveaxis(x_valid, -1, 1)\nx_test = np.moveaxis(x_test, -1, 1)\n\nprint(x_train.shape)\n#print(x_train.shape)\nprint(x_test.shape)\n\nenc = LabelBinarizer()\n\ny_train = enc.fit_transform(y_train)\ny_test = enc.fit_transform(y_test)\n\nx_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2)\n\nIMG_SIZE = 299\n\ntrain_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\nvalid_ds = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\ntest_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n\"\"\"\ntrain_ds = train_ds.map(\n    lambda x,y: (preprocess_input(x), y)\n)\nvalid_ds = valid_ds.map(\n    lambda x,y: (preprocess_input(x), y)\n)\ntest_ds = test_ds.map(\n    lambda x,y: (preprocess_input(x), y)\n)\"\"\"\n\nresize_and_rescale = tf.keras.Sequential([\n    Resizing(IMG_SIZE, IMG_SIZE),\n    Rescaling(1./255, offset=-1),\n])\n\naug_ds = train_ds.map(\n  lambda x, y: (resize_and_rescale(x, training=True), y)\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T15:03:37.748266Z","iopub.execute_input":"2023-04-23T15:03:37.749168Z","iopub.status.idle":"2023-04-23T15:03:38.541467Z","shell.execute_reply.started":"2023-04-23T15:03:37.749109Z","shell.execute_reply":"2023-04-23T15:03:38.539683Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"(50000, 32, 32, 3)\n(10000, 32, 32, 3)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/2247020463.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mx_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'x_valid' is not defined"],"ename":"NameError","evalue":"name 'x_valid' is not defined","output_type":"error"}]},{"cell_type":"code","source":"from keras.applications.inception_v3 import preprocess_input\nfrom tensorflow.data import Dataset\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.image import resize\n\nenc = LabelBinarizer()\n\ny_train = enc.fit_transform(y_train)\ny_test = enc.fit_transform(y_test)\n\nx_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2)\n\nIMG_SIZE = 299\n\ntrain_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\nvalid_ds = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\ntest_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n\ntrain_ds = train_ds.map(\n    lambda x,y: (tf.image.resize(x, (299, 299)), y)\n)\nvalid_ds = valid_ds.map(\n    lambda x,y: (tf.image.resize(x, (299, 299)), y)\n)\ntest_ds = test_ds.map(\n    lambda x,y: (tf.image.resize(x, (299, 299)), y)\n)\n\ntrain_ds = train_ds.map(\n    lambda x,y: (preprocess_input(x, data_format=), y)\n)\nvalid_ds = valid_ds.map(\n    lambda x,y: (preprocess_input(x), y)\n)\ntest_ds = test_ds.map(\n    lambda x,y: (preprocess_input(x), y)\n)","metadata":{"execution":{"iopub.status.busy":"2023-04-23T15:13:50.463344Z","iopub.execute_input":"2023-04-23T15:13:50.464110Z","iopub.status.idle":"2023-04-23T15:13:52.578007Z","shell.execute_reply.started":"2023-04-23T15:13:50.464069Z","shell.execute_reply":"2023-04-23T15:13:52.576698Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"print(train_ds)","metadata":{"execution":{"iopub.status.busy":"2023-04-23T15:17:34.420210Z","iopub.execute_input":"2023-04-23T15:17:34.421046Z","iopub.status.idle":"2023-04-23T15:17:34.426864Z","shell.execute_reply.started":"2023-04-23T15:17:34.420993Z","shell.execute_reply":"2023-04-23T15:17:34.425586Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"<MapDataset element_spec=(TensorSpec(shape=(299, 299, 3), dtype=tf.float32, name=None), TensorSpec(shape=(100,), dtype=tf.int64, name=None))>\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Inception v4 Implementation","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n\n# create the base pre-trained model\nbase_model = InceptionV3(weights='imagenet', include_top=False)\n\n# add own top to pre-trained model\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)\n\npredictions = Dense(100, activation='softmax')(x)\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# first train only the top layers\n# freeze all convolutional InceptionV3 layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy')\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T15:17:52.578187Z","iopub.execute_input":"2023-04-23T15:17:52.578630Z","iopub.status.idle":"2023-04-23T15:17:59.426910Z","shell.execute_reply.started":"2023-04-23T15:17:52.578583Z","shell.execute_reply":"2023-04-23T15:17:59.425647Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n87910968/87910968 [==============================] - 3s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, TerminateOnNaN\nimport datetime\n\nlogdir = \"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n\n\n\n# at this point, the top layers are well trained and we can start fine-tuning\n# convolutional layers from inception V3. We will freeze the bottom N layers\n# and train the remaining top layers.\nmodel.fit(train_ds,\n          epochs=5,\n          batch_size=1024,\n          validation_data=valid_ds,\n          validation_batch_size=1024,\n          callbacks=[\n              TensorBoard(\n                  log_dir=logdir,\n                  histogram_freq=1\n              ),\n              EarlyStopping(\n                  monitor='val_top_1_accuracy',\n                  patience=10,\n                  restore_best_weights=True,\n              ),\n              ModelCheckpoint(\n                  logdir+'/checkpoint',\n                  monitor='val_top_1_accuracy',\n                  save_best_only=True,\n              ),\n              TerminateOnNaN(),\n          ],\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T15:18:12.735008Z","iopub.execute_input":"2023-04-23T15:18:12.736210Z","iopub.status.idle":"2023-04-23T15:18:13.193941Z","shell.execute_reply.started":"2023-04-23T15:18:12.736159Z","shell.execute_reply":"2023-04-23T15:18:13.192041Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/2960169529.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m                   \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m               ),\n\u001b[0;32m---> 31\u001b[0;31m               \u001b[0mTerminateOnNaN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m           ],\n\u001b[1;32m     33\u001b[0m )\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/input_spec.py\", line 251, in assert_input_compatibility\n        f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer 'model' (type Functional).\n    \n    Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (299, 299, 3)\n    \n    Call arguments received by layer 'model' (type Functional):\n      • inputs=tf.Tensor(shape=(299, 299, 3), dtype=float32)\n      • training=True\n      • mask=None\n"],"ename":"ValueError","evalue":"in user code:\n\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.7/site-packages/keras/engine/input_spec.py\", line 251, in assert_input_compatibility\n        f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer 'model' (type Functional).\n    \n    Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (299, 299, 3)\n    \n    Call arguments received by layer 'model' (type Functional):\n      • inputs=tf.Tensor(shape=(299, 299, 3), dtype=float32)\n      • training=True\n      • mask=None\n","output_type":"error"}]},{"cell_type":"code","source":"# let's visualize layer names and layer indices to see how many layers\n# we should freeze:\nfor i, layer in enumerate(base_model.layers):\n   print(i, layer.name)\n\n# we chose to train the top 2 inception blocks, i.e. we will freeze\n# the first 249 layers and unfreeze the rest:\nfor layer in model.layers[:249]:\n   layer.trainable = False\nfor layer in model.layers[249:]:\n   layer.trainable = True\n\n# we need to recompile the model for these modifications to take effect\nmodel.compile(optimizer='adam', loss='categorical_crossentropy')\n# run previous block to train model again, but with more epochs","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%load_external tensorboard","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%tensorboard --logdir ./logs/fit","metadata":{},"execution_count":null,"outputs":[]}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Importing the CIFAR-100 dataset","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\n\n(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data(label_mode='fine')\n\nprint(x_train.shape, y_train.shape)\nprint(x_test.shape, y_test.shape)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-05-03T17:36:51.991791Z","iopub.execute_input":"2023-05-03T17:36:51.992285Z","iopub.status.idle":"2023-05-03T17:37:12.793538Z","shell.execute_reply.started":"2023-05-03T17:36:51.992248Z","shell.execute_reply":"2023-05-03T17:37:12.792109Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n169001437/169001437 [==============================] - 12s 0us/step\n(50000, 32, 32, 3) (50000, 1)\n(10000, 32, 32, 3) (10000, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(tf.config.list_physical_devices('GPU'))\n!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2023-05-03T17:37:48.477105Z","iopub.execute_input":"2023-05-03T17:37:48.478421Z","iopub.status.idle":"2023-05-03T17:37:49.487586Z","shell.execute_reply.started":"2023-05-03T17:37:48.478370Z","shell.execute_reply":"2023-05-03T17:37:49.486334Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\nWed May  3 17:37:49 2023       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.161.03   Driver Version: 470.161.03   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   33C    P0    26W / 250W |      2MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.applications.inception_v3 import preprocess_input\nfrom tensorflow.data import Dataset\nfrom keras.layers import Resizing, Rescaling\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\n\nenc = LabelBinarizer()\n\ny_train = enc.fit_transform(y_train)\ny_test = enc.fit_transform(y_test)\n\nprint(x_train.shape)\nprint(x_test.shape)\n\n#x_train = np.moveaxis(x_train, -1, 1)\n#x_test = np.moveaxis(x_test, -1, 1)\n\nprint(x_train.shape)\nprint(x_test.shape)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-03T17:37:53.498899Z","iopub.execute_input":"2023-05-03T17:37:53.499756Z","iopub.status.idle":"2023-05-03T17:37:54.144338Z","shell.execute_reply.started":"2023-05-03T17:37:53.499709Z","shell.execute_reply":"2023-05-03T17:37:54.143105Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"(50000, 32, 32, 3)\n(10000, 32, 32, 3)\n(50000, 32, 32, 3)\n(10000, 32, 32, 3)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Inception v4 Implementation","metadata":{}},{"cell_type":"code","source":"test = x_train[0].reshape((1, 32, 32, 3))\n\nasd = resize_rescale(test)\n\nprint(asd.dtype)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T08:57:35.525792Z","iopub.execute_input":"2023-05-03T08:57:35.526730Z","iopub.status.idle":"2023-05-03T08:57:35.542066Z","shell.execute_reply.started":"2023-05-03T08:57:35.526689Z","shell.execute_reply":"2023-05-03T08:57:35.540526Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"<dtype: 'float32'>\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Concatenate, Input\nfrom keras.metrics import TopKCategoricalAccuracy\n\nresize_rescale = tf.keras.Sequential([\n    Input(shape=(32, 32, 3)),\n    Resizing(299, 299),\n    Rescaling(1./255, offset=-1),\n])\n# create the base pre-trained model\nbase_model = InceptionV3(input_tensor=resize_rescale.output, weights='imagenet', include_top=False)\n\n\n# add own top to pre-trained model\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)\n\npredictions = Dense(100, activation='softmax')(x)\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\n# first train only the top layers\n# freeze all convolutional InceptionV3 layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy',\n              metrics=[\n                  TopKCategoricalAccuracy(k=1, name='top_1_accuracy'),\n                  TopKCategoricalAccuracy(k=5, name='top_5_accuracy'),\n              ])\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-03T17:38:01.682913Z","iopub.execute_input":"2023-05-03T17:38:01.683838Z","iopub.status.idle":"2023-05-03T17:38:10.838360Z","shell.execute_reply.started":"2023-05-03T17:38:01.683784Z","shell.execute_reply":"2023-05-03T17:38:10.837307Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n87910968/87910968 [==============================] - 4s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport itertools\nfrom sklearn.metrics import confusion_matrix\n\ndef plot_confusion_matrix(cm, class_names):\n  \"\"\"\n  Returns a matplotlib figure containing the plotted confusion matrix.\n\n  Args:\n    cm (array, shape = [n, n]): a confusion matrix of integer classes\n    class_names (array, shape = [n]): String names of the integer classes\n  \"\"\"\n  figure = plt.figure(figsize=(8, 8))\n  plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n  plt.title(\"Confusion matrix\")\n  plt.colorbar()\n  tick_marks = np.arange(len(class_names))\n  plt.xticks(tick_marks, class_names, rotation=45)\n  plt.yticks(tick_marks, class_names)\n\n  # Compute the labels from the normalized confusion matrix.\n  labels = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n\n  # Use white text if squares are dark; otherwise black.\n  threshold = cm.max() / 2.\n  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    color = \"white\" if cm[i, j] > threshold else \"black\"\n    plt.text(j, i, labels[i, j], horizontalalignment=\"center\", color=color)\n\n  plt.tight_layout()\n  plt.ylabel('True label')\n  plt.xlabel('Predicted label')\n  return figure\n\n\ndef log_confusion_matrix(epoch, logs):\n  # Use the model to predict the values from the validation dataset.\n  test_pred_raw = model.predict(x_test)\n  test_pred = np.argmax(test_pred_raw, axis=1)\n\n  # Calculate the confusion matrix.\n  cm = sklearn.metrics.confusion_matrix(y_test, test_pred)\n  # Log the confusion matrix as an image summary.\n  figure = plot_confusion_matrix(cm, class_names=np.arange(100))\n  cm_image = plot_to_image(figure)\n\n  # Log the confusion matrix as an image summary.\n  with file_writer_cm.as_default():\n    tf.summary.image(\"epoch_confusion_matrix\", cm_image, step=epoch)\n\ndef plot_to_image(figure):\n  \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n  returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n  # Save the plot to a PNG in memory.\n  buf = io.BytesIO()\n  plt.savefig(buf, format='png')\n  # Closing the figure prevents it from being displayed directly inside\n  # the notebook.\n  plt.close(figure)\n  buf.seek(0)\n  # Convert PNG buffer to TF image\n  image = tf.image.decode_png(buf.getvalue(), channels=4)\n  # Add the batch dimension\n  image = tf.expand_dims(image, 0)\n  return image","metadata":{"execution":{"iopub.status.busy":"2023-04-27T13:56:44.668357Z","iopub.execute_input":"2023-04-27T13:56:44.669308Z","iopub.status.idle":"2023-04-27T13:56:44.683052Z","shell.execute_reply.started":"2023-04-27T13:56:44.669253Z","shell.execute_reply":"2023-04-27T13:56:44.682007Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# let's visualize layer names and layer indices to see how many layers\n# we should freeze:\nfor i, layer in enumerate(base_model.layers):\n   print(i, layer.name)\n\n# we chose to train the top 2 inception blocks, i.e. we will freeze\n# the first 249 layers and unfreeze the rest:\nfor layer in model.layers[:249]:\n   layer.trainable = False\nfor layer in model.layers[249:]:\n   layer.trainable = True\n\n# we need to recompile the model for these modifications to take effect\nmodel.compile(optimizer='adam', loss='categorical_crossentropy',\n              metrics=[\n                  TopKCategoricalAccuracy(k=1, name='top_1_accuracy'),\n                  TopKCategoricalAccuracy(k=5, name='top_5_accuracy'),\n              ])\n# run previous block to train model again, but with more epochs","metadata":{"execution":{"iopub.status.busy":"2023-05-03T17:38:24.542943Z","iopub.execute_input":"2023-05-03T17:38:24.543664Z","iopub.status.idle":"2023-05-03T17:38:24.584124Z","shell.execute_reply.started":"2023-05-03T17:38:24.543627Z","shell.execute_reply":"2023-05-03T17:38:24.582837Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"0 input_1\n1 resizing\n2 rescaling\n3 conv2d\n4 batch_normalization\n5 activation\n6 conv2d_1\n7 batch_normalization_1\n8 activation_1\n9 conv2d_2\n10 batch_normalization_2\n11 activation_2\n12 max_pooling2d\n13 conv2d_3\n14 batch_normalization_3\n15 activation_3\n16 conv2d_4\n17 batch_normalization_4\n18 activation_4\n19 max_pooling2d_1\n20 conv2d_8\n21 batch_normalization_8\n22 activation_8\n23 conv2d_6\n24 conv2d_9\n25 batch_normalization_6\n26 batch_normalization_9\n27 activation_6\n28 activation_9\n29 average_pooling2d\n30 conv2d_5\n31 conv2d_7\n32 conv2d_10\n33 conv2d_11\n34 batch_normalization_5\n35 batch_normalization_7\n36 batch_normalization_10\n37 batch_normalization_11\n38 activation_5\n39 activation_7\n40 activation_10\n41 activation_11\n42 mixed0\n43 conv2d_15\n44 batch_normalization_15\n45 activation_15\n46 conv2d_13\n47 conv2d_16\n48 batch_normalization_13\n49 batch_normalization_16\n50 activation_13\n51 activation_16\n52 average_pooling2d_1\n53 conv2d_12\n54 conv2d_14\n55 conv2d_17\n56 conv2d_18\n57 batch_normalization_12\n58 batch_normalization_14\n59 batch_normalization_17\n60 batch_normalization_18\n61 activation_12\n62 activation_14\n63 activation_17\n64 activation_18\n65 mixed1\n66 conv2d_22\n67 batch_normalization_22\n68 activation_22\n69 conv2d_20\n70 conv2d_23\n71 batch_normalization_20\n72 batch_normalization_23\n73 activation_20\n74 activation_23\n75 average_pooling2d_2\n76 conv2d_19\n77 conv2d_21\n78 conv2d_24\n79 conv2d_25\n80 batch_normalization_19\n81 batch_normalization_21\n82 batch_normalization_24\n83 batch_normalization_25\n84 activation_19\n85 activation_21\n86 activation_24\n87 activation_25\n88 mixed2\n89 conv2d_27\n90 batch_normalization_27\n91 activation_27\n92 conv2d_28\n93 batch_normalization_28\n94 activation_28\n95 conv2d_26\n96 conv2d_29\n97 batch_normalization_26\n98 batch_normalization_29\n99 activation_26\n100 activation_29\n101 max_pooling2d_2\n102 mixed3\n103 conv2d_34\n104 batch_normalization_34\n105 activation_34\n106 conv2d_35\n107 batch_normalization_35\n108 activation_35\n109 conv2d_31\n110 conv2d_36\n111 batch_normalization_31\n112 batch_normalization_36\n113 activation_31\n114 activation_36\n115 conv2d_32\n116 conv2d_37\n117 batch_normalization_32\n118 batch_normalization_37\n119 activation_32\n120 activation_37\n121 average_pooling2d_3\n122 conv2d_30\n123 conv2d_33\n124 conv2d_38\n125 conv2d_39\n126 batch_normalization_30\n127 batch_normalization_33\n128 batch_normalization_38\n129 batch_normalization_39\n130 activation_30\n131 activation_33\n132 activation_38\n133 activation_39\n134 mixed4\n135 conv2d_44\n136 batch_normalization_44\n137 activation_44\n138 conv2d_45\n139 batch_normalization_45\n140 activation_45\n141 conv2d_41\n142 conv2d_46\n143 batch_normalization_41\n144 batch_normalization_46\n145 activation_41\n146 activation_46\n147 conv2d_42\n148 conv2d_47\n149 batch_normalization_42\n150 batch_normalization_47\n151 activation_42\n152 activation_47\n153 average_pooling2d_4\n154 conv2d_40\n155 conv2d_43\n156 conv2d_48\n157 conv2d_49\n158 batch_normalization_40\n159 batch_normalization_43\n160 batch_normalization_48\n161 batch_normalization_49\n162 activation_40\n163 activation_43\n164 activation_48\n165 activation_49\n166 mixed5\n167 conv2d_54\n168 batch_normalization_54\n169 activation_54\n170 conv2d_55\n171 batch_normalization_55\n172 activation_55\n173 conv2d_51\n174 conv2d_56\n175 batch_normalization_51\n176 batch_normalization_56\n177 activation_51\n178 activation_56\n179 conv2d_52\n180 conv2d_57\n181 batch_normalization_52\n182 batch_normalization_57\n183 activation_52\n184 activation_57\n185 average_pooling2d_5\n186 conv2d_50\n187 conv2d_53\n188 conv2d_58\n189 conv2d_59\n190 batch_normalization_50\n191 batch_normalization_53\n192 batch_normalization_58\n193 batch_normalization_59\n194 activation_50\n195 activation_53\n196 activation_58\n197 activation_59\n198 mixed6\n199 conv2d_64\n200 batch_normalization_64\n201 activation_64\n202 conv2d_65\n203 batch_normalization_65\n204 activation_65\n205 conv2d_61\n206 conv2d_66\n207 batch_normalization_61\n208 batch_normalization_66\n209 activation_61\n210 activation_66\n211 conv2d_62\n212 conv2d_67\n213 batch_normalization_62\n214 batch_normalization_67\n215 activation_62\n216 activation_67\n217 average_pooling2d_6\n218 conv2d_60\n219 conv2d_63\n220 conv2d_68\n221 conv2d_69\n222 batch_normalization_60\n223 batch_normalization_63\n224 batch_normalization_68\n225 batch_normalization_69\n226 activation_60\n227 activation_63\n228 activation_68\n229 activation_69\n230 mixed7\n231 conv2d_72\n232 batch_normalization_72\n233 activation_72\n234 conv2d_73\n235 batch_normalization_73\n236 activation_73\n237 conv2d_70\n238 conv2d_74\n239 batch_normalization_70\n240 batch_normalization_74\n241 activation_70\n242 activation_74\n243 conv2d_71\n244 conv2d_75\n245 batch_normalization_71\n246 batch_normalization_75\n247 activation_71\n248 activation_75\n249 max_pooling2d_3\n250 mixed8\n251 conv2d_80\n252 batch_normalization_80\n253 activation_80\n254 conv2d_77\n255 conv2d_81\n256 batch_normalization_77\n257 batch_normalization_81\n258 activation_77\n259 activation_81\n260 conv2d_78\n261 conv2d_79\n262 conv2d_82\n263 conv2d_83\n264 average_pooling2d_7\n265 conv2d_76\n266 batch_normalization_78\n267 batch_normalization_79\n268 batch_normalization_82\n269 batch_normalization_83\n270 conv2d_84\n271 batch_normalization_76\n272 activation_78\n273 activation_79\n274 activation_82\n275 activation_83\n276 batch_normalization_84\n277 activation_76\n278 mixed9_0\n279 concatenate\n280 activation_84\n281 mixed9\n282 conv2d_89\n283 batch_normalization_89\n284 activation_89\n285 conv2d_86\n286 conv2d_90\n287 batch_normalization_86\n288 batch_normalization_90\n289 activation_86\n290 activation_90\n291 conv2d_87\n292 conv2d_88\n293 conv2d_91\n294 conv2d_92\n295 average_pooling2d_8\n296 conv2d_85\n297 batch_normalization_87\n298 batch_normalization_88\n299 batch_normalization_91\n300 batch_normalization_92\n301 conv2d_93\n302 batch_normalization_85\n303 activation_87\n304 activation_88\n305 activation_91\n306 activation_92\n307 batch_normalization_93\n308 activation_85\n309 mixed9_1\n310 concatenate_1\n311 activation_93\n312 mixed10\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pyNVML\nimport pynvml as nvidia_smi\n\nnvidia_smi.nvmlInit()\n\nhandle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\ninfo = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\ntotal_gpu_memory = info.total\n# Weights are float32 -> 4 bytes\nmodel_size = model.count_params() * 4\n# Rescaling layer returns float32\n# 299*299 pixels, RGB colors\nimage_size = 4 * 299 * 299 * 3\nMAX_BATCH_SIZE = int(np.floor(total_gpu_memory / (model_size + image_size)))\nMAX_BATCH_SIZE_LOG2 = int(2 ** np.floor(np.log2(MAX_BATCH_SIZE)))\nprint(MAX_BATCH_SIZE)\nprint(MAX_BATCH_SIZE_LOG2)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T17:38:34.944670Z","iopub.execute_input":"2023-05-03T17:38:34.945356Z","iopub.status.idle":"2023-05-03T17:38:45.587846Z","shell.execute_reply.started":"2023-05-03T17:38:34.945317Z","shell.execute_reply":"2023-05-03T17:38:45.586038Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pyNVML in /opt/conda/lib/python3.7/site-packages (11.5.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m175\n128\n","output_type":"stream"}]},{"cell_type":"code","source":"test = x_train[0].reshape((1, 32, 32, 3))\nasd = resize_rescale(test)\n\nprint(asd.dtype)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T09:28:01.826993Z","iopub.execute_input":"2023-05-03T09:28:01.827557Z","iopub.status.idle":"2023-05-03T09:28:01.837279Z","shell.execute_reply.started":"2023-05-03T09:28:01.827513Z","shell.execute_reply":"2023-05-03T09:28:01.836135Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"<dtype: 'float32'>\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, TerminateOnNaN\nimport datetime\n\nlogdir = \"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n\n#cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n\n# at this point, the top layers are well trained and we can start fine-tuning\n# convolutional layers from inception V3. We will freeze the bottom N layers\n# and train the remaining top layers.\nmodel.fit(x_train, y_train,\n          epochs=200,\n          batch_size=MAX_BATCH_SIZE_LOG2,\n          validation_batch_size=MAX_BATCH_SIZE_LOG2,\n          verbose=1,\n          callbacks=[\n              TensorBoard(\n                  log_dir=logdir,\n                  histogram_freq=1\n              ),\n              EarlyStopping(\n                  monitor='val_top_1_accuracy',\n                  patience=25,\n                  restore_best_weights=True,\n              ),\n              ModelCheckpoint(\n                  logdir+'/checkpoint',\n                  monitor='val_top_1_accuracy',\n                  save_best_only=True,\n              ),\n              #TerminateOnNaN(),\n              #cm_callback,\n          ],\n)\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-05-03T17:39:04.245573Z","iopub.execute_input":"2023-05-03T17:39:04.245979Z","iopub.status.idle":"2023-05-03T22:07:05.306759Z","shell.execute_reply.started":"2023-05-03T17:39:04.245936Z","shell.execute_reply":"2023-05-03T22:07:05.303283Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Epoch 1/200\n391/391 [==============================] - 136s 304ms/step - loss: 1.4800 - top_1_accuracy: 0.5897 - top_5_accuracy: 0.8655\nEpoch 2/200\n391/391 [==============================] - 117s 300ms/step - loss: 0.8406 - top_1_accuracy: 0.7517 - top_5_accuracy: 0.9514\nEpoch 3/200\n391/391 [==============================] - 117s 300ms/step - loss: 0.5604 - top_1_accuracy: 0.8258 - top_5_accuracy: 0.9774\nEpoch 4/200\n391/391 [==============================] - 117s 300ms/step - loss: 0.3857 - top_1_accuracy: 0.8763 - top_5_accuracy: 0.9904\nEpoch 5/200\n391/391 [==============================] - 117s 300ms/step - loss: 0.2568 - top_1_accuracy: 0.9192 - top_5_accuracy: 0.9958\nEpoch 6/200\n391/391 [==============================] - 117s 300ms/step - loss: 0.1908 - top_1_accuracy: 0.9372 - top_5_accuracy: 0.9985\nEpoch 7/200\n391/391 [==============================] - 117s 300ms/step - loss: 0.1517 - top_1_accuracy: 0.9501 - top_5_accuracy: 0.9987\nEpoch 8/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.1335 - top_1_accuracy: 0.9563 - top_5_accuracy: 0.9992\nEpoch 9/200\n391/391 [==============================] - 117s 300ms/step - loss: 0.1064 - top_1_accuracy: 0.9663 - top_5_accuracy: 0.9996\nEpoch 10/200\n391/391 [==============================] - 117s 300ms/step - loss: 0.0993 - top_1_accuracy: 0.9691 - top_5_accuracy: 0.9993\nEpoch 11/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0967 - top_1_accuracy: 0.9699 - top_5_accuracy: 0.9996\nEpoch 12/200\n391/391 [==============================] - 117s 300ms/step - loss: 0.0902 - top_1_accuracy: 0.9709 - top_5_accuracy: 0.9997\nEpoch 13/200\n391/391 [==============================] - 117s 300ms/step - loss: 0.0766 - top_1_accuracy: 0.9763 - top_5_accuracy: 0.9997\nEpoch 14/200\n391/391 [==============================] - 117s 300ms/step - loss: 0.0670 - top_1_accuracy: 0.9792 - top_5_accuracy: 0.9997\nEpoch 15/200\n391/391 [==============================] - 117s 299ms/step - loss: 0.0733 - top_1_accuracy: 0.9775 - top_5_accuracy: 0.9997\nEpoch 16/200\n391/391 [==============================] - 117s 299ms/step - loss: 0.0650 - top_1_accuracy: 0.9807 - top_5_accuracy: 0.9996\nEpoch 17/200\n391/391 [==============================] - 117s 300ms/step - loss: 0.0616 - top_1_accuracy: 0.9817 - top_5_accuracy: 0.9998\nEpoch 18/200\n391/391 [==============================] - 117s 299ms/step - loss: 0.0593 - top_1_accuracy: 0.9816 - top_5_accuracy: 0.9997\nEpoch 19/200\n391/391 [==============================] - 117s 299ms/step - loss: 0.0603 - top_1_accuracy: 0.9819 - top_5_accuracy: 0.9998\nEpoch 20/200\n391/391 [==============================] - 117s 300ms/step - loss: 0.0557 - top_1_accuracy: 0.9832 - top_5_accuracy: 0.9997\nEpoch 21/200\n391/391 [==============================] - 117s 300ms/step - loss: 0.0501 - top_1_accuracy: 0.9849 - top_5_accuracy: 0.9997\nEpoch 22/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0499 - top_1_accuracy: 0.9854 - top_5_accuracy: 0.9998\nEpoch 23/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0546 - top_1_accuracy: 0.9836 - top_5_accuracy: 0.9997\nEpoch 24/200\n391/391 [==============================] - 118s 303ms/step - loss: 0.0451 - top_1_accuracy: 0.9862 - top_5_accuracy: 0.9998\nEpoch 25/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0472 - top_1_accuracy: 0.9862 - top_5_accuracy: 0.9998\nEpoch 26/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0409 - top_1_accuracy: 0.9877 - top_5_accuracy: 0.9999\nEpoch 27/200\n391/391 [==============================] - 118s 303ms/step - loss: 0.0441 - top_1_accuracy: 0.9872 - top_5_accuracy: 0.9997\nEpoch 28/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0369 - top_1_accuracy: 0.9890 - top_5_accuracy: 0.9998\nEpoch 29/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0412 - top_1_accuracy: 0.9884 - top_5_accuracy: 0.9999\nEpoch 30/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0383 - top_1_accuracy: 0.9887 - top_5_accuracy: 0.9999\nEpoch 31/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0420 - top_1_accuracy: 0.9868 - top_5_accuracy: 0.9999\nEpoch 32/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0390 - top_1_accuracy: 0.9879 - top_5_accuracy: 0.9999\nEpoch 33/200\n391/391 [==============================] - 119s 303ms/step - loss: 0.0273 - top_1_accuracy: 0.9914 - top_5_accuracy: 0.9999\nEpoch 34/200\n391/391 [==============================] - 119s 304ms/step - loss: 0.0284 - top_1_accuracy: 0.9917 - top_5_accuracy: 0.9999\nEpoch 35/200\n391/391 [==============================] - 119s 303ms/step - loss: 0.0392 - top_1_accuracy: 0.9882 - top_5_accuracy: 0.9998\nEpoch 36/200\n391/391 [==============================] - 118s 303ms/step - loss: 0.0298 - top_1_accuracy: 0.9910 - top_5_accuracy: 0.9999\nEpoch 37/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0296 - top_1_accuracy: 0.9914 - top_5_accuracy: 0.9999\nEpoch 38/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0318 - top_1_accuracy: 0.9910 - top_5_accuracy: 0.9998\nEpoch 39/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0330 - top_1_accuracy: 0.9900 - top_5_accuracy: 0.9999\nEpoch 40/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0287 - top_1_accuracy: 0.9914 - top_5_accuracy: 0.9999\nEpoch 41/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0263 - top_1_accuracy: 0.9923 - top_5_accuracy: 0.9999\nEpoch 42/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0265 - top_1_accuracy: 0.9921 - top_5_accuracy: 0.9999\nEpoch 43/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0296 - top_1_accuracy: 0.9909 - top_5_accuracy: 0.9999\nEpoch 44/200\n391/391 [==============================] - 118s 303ms/step - loss: 0.0270 - top_1_accuracy: 0.9919 - top_5_accuracy: 0.9999\nEpoch 45/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0245 - top_1_accuracy: 0.9929 - top_5_accuracy: 0.9999\nEpoch 46/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0292 - top_1_accuracy: 0.9918 - top_5_accuracy: 0.9999\nEpoch 47/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0239 - top_1_accuracy: 0.9932 - top_5_accuracy: 0.9999\nEpoch 48/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0257 - top_1_accuracy: 0.9925 - top_5_accuracy: 0.9999\nEpoch 49/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0147 - top_1_accuracy: 0.9959 - top_5_accuracy: 0.9999\nEpoch 50/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0267 - top_1_accuracy: 0.9925 - top_5_accuracy: 0.9999\nEpoch 51/200\n391/391 [==============================] - 118s 303ms/step - loss: 0.0333 - top_1_accuracy: 0.9905 - top_5_accuracy: 0.9999\nEpoch 52/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0200 - top_1_accuracy: 0.9938 - top_5_accuracy: 1.0000\nEpoch 53/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0208 - top_1_accuracy: 0.9943 - top_5_accuracy: 0.9999\nEpoch 54/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0243 - top_1_accuracy: 0.9933 - top_5_accuracy: 0.9999\nEpoch 55/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0231 - top_1_accuracy: 0.9928 - top_5_accuracy: 0.9999\nEpoch 56/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0186 - top_1_accuracy: 0.9943 - top_5_accuracy: 1.0000\nEpoch 57/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0173 - top_1_accuracy: 0.9946 - top_5_accuracy: 0.9999\nEpoch 58/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0195 - top_1_accuracy: 0.9950 - top_5_accuracy: 0.9999\nEpoch 59/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0240 - top_1_accuracy: 0.9933 - top_5_accuracy: 0.9999\nEpoch 60/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0238 - top_1_accuracy: 0.9934 - top_5_accuracy: 0.9999\nEpoch 61/200\n391/391 [==============================] - 118s 303ms/step - loss: 0.0196 - top_1_accuracy: 0.9939 - top_5_accuracy: 1.0000\nEpoch 62/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0182 - top_1_accuracy: 0.9950 - top_5_accuracy: 0.9999\nEpoch 63/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0166 - top_1_accuracy: 0.9955 - top_5_accuracy: 0.9999\nEpoch 64/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0192 - top_1_accuracy: 0.9944 - top_5_accuracy: 0.9999\nEpoch 65/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0244 - top_1_accuracy: 0.9935 - top_5_accuracy: 0.9999\nEpoch 66/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0168 - top_1_accuracy: 0.9951 - top_5_accuracy: 0.9999\nEpoch 67/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0219 - top_1_accuracy: 0.9938 - top_5_accuracy: 0.9999\nEpoch 68/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0120 - top_1_accuracy: 0.9965 - top_5_accuracy: 0.9999\nEpoch 69/200\n391/391 [==============================] - 118s 303ms/step - loss: 0.0136 - top_1_accuracy: 0.9961 - top_5_accuracy: 1.0000\nEpoch 70/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0191 - top_1_accuracy: 0.9953 - top_5_accuracy: 0.9999\nEpoch 71/200\n391/391 [==============================] - 119s 303ms/step - loss: 0.0212 - top_1_accuracy: 0.9940 - top_5_accuracy: 1.0000\nEpoch 72/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0179 - top_1_accuracy: 0.9948 - top_5_accuracy: 0.9999\nEpoch 73/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0129 - top_1_accuracy: 0.9962 - top_5_accuracy: 0.9999\nEpoch 74/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0146 - top_1_accuracy: 0.9957 - top_5_accuracy: 0.9999\nEpoch 75/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0179 - top_1_accuracy: 0.9945 - top_5_accuracy: 0.9999\nEpoch 76/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0165 - top_1_accuracy: 0.9953 - top_5_accuracy: 1.0000\nEpoch 77/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0126 - top_1_accuracy: 0.9963 - top_5_accuracy: 1.0000\nEpoch 78/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0168 - top_1_accuracy: 0.9952 - top_5_accuracy: 0.9999\nEpoch 79/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0188 - top_1_accuracy: 0.9947 - top_5_accuracy: 0.9999\nEpoch 80/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0167 - top_1_accuracy: 0.9953 - top_5_accuracy: 0.9999\nEpoch 81/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0207 - top_1_accuracy: 0.9945 - top_5_accuracy: 1.0000\nEpoch 82/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0124 - top_1_accuracy: 0.9964 - top_5_accuracy: 0.9999\nEpoch 83/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0130 - top_1_accuracy: 0.9962 - top_5_accuracy: 1.0000\nEpoch 84/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0147 - top_1_accuracy: 0.9957 - top_5_accuracy: 1.0000\nEpoch 85/200\n391/391 [==============================] - 118s 301ms/step - loss: 0.0129 - top_1_accuracy: 0.9965 - top_5_accuracy: 1.0000\nEpoch 86/200\n391/391 [==============================] - 118s 303ms/step - loss: 0.0089 - top_1_accuracy: 0.9972 - top_5_accuracy: 1.0000\nEpoch 87/200\n391/391 [==============================] - 118s 303ms/step - loss: 0.0155 - top_1_accuracy: 0.9953 - top_5_accuracy: 1.0000\nEpoch 88/200\n391/391 [==============================] - 119s 303ms/step - loss: 0.0106 - top_1_accuracy: 0.9969 - top_5_accuracy: 1.0000\nEpoch 89/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0142 - top_1_accuracy: 0.9962 - top_5_accuracy: 1.0000\nEpoch 90/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0149 - top_1_accuracy: 0.9962 - top_5_accuracy: 0.9999\nEpoch 91/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0106 - top_1_accuracy: 0.9970 - top_5_accuracy: 1.0000\nEpoch 92/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0150 - top_1_accuracy: 0.9958 - top_5_accuracy: 1.0000\nEpoch 93/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0129 - top_1_accuracy: 0.9966 - top_5_accuracy: 1.0000\nEpoch 94/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0130 - top_1_accuracy: 0.9961 - top_5_accuracy: 1.0000\nEpoch 95/200\n391/391 [==============================] - 119s 304ms/step - loss: 0.0163 - top_1_accuracy: 0.9959 - top_5_accuracy: 0.9999\nEpoch 96/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0137 - top_1_accuracy: 0.9963 - top_5_accuracy: 1.0000\nEpoch 97/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0127 - top_1_accuracy: 0.9963 - top_5_accuracy: 1.0000\nEpoch 98/200\n391/391 [==============================] - 118s 303ms/step - loss: 0.0124 - top_1_accuracy: 0.9957 - top_5_accuracy: 1.0000\nEpoch 99/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0130 - top_1_accuracy: 0.9960 - top_5_accuracy: 1.0000\nEpoch 100/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0081 - top_1_accuracy: 0.9977 - top_5_accuracy: 1.0000\nEpoch 101/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0150 - top_1_accuracy: 0.9962 - top_5_accuracy: 1.0000\nEpoch 102/200\n391/391 [==============================] - 119s 303ms/step - loss: 0.0154 - top_1_accuracy: 0.9956 - top_5_accuracy: 1.0000\nEpoch 103/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0089 - top_1_accuracy: 0.9973 - top_5_accuracy: 0.9999\nEpoch 104/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0112 - top_1_accuracy: 0.9969 - top_5_accuracy: 0.9999\nEpoch 105/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0142 - top_1_accuracy: 0.9961 - top_5_accuracy: 1.0000\nEpoch 106/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0154 - top_1_accuracy: 0.9955 - top_5_accuracy: 1.0000\nEpoch 107/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0118 - top_1_accuracy: 0.9971 - top_5_accuracy: 0.9999\nEpoch 108/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0129 - top_1_accuracy: 0.9969 - top_5_accuracy: 1.0000\nEpoch 109/200\n391/391 [==============================] - 119s 303ms/step - loss: 0.0127 - top_1_accuracy: 0.9965 - top_5_accuracy: 0.9999\nEpoch 110/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0085 - top_1_accuracy: 0.9974 - top_5_accuracy: 1.0000\nEpoch 111/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0089 - top_1_accuracy: 0.9977 - top_5_accuracy: 1.0000\nEpoch 112/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0142 - top_1_accuracy: 0.9959 - top_5_accuracy: 1.0000\nEpoch 113/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0147 - top_1_accuracy: 0.9958 - top_5_accuracy: 1.0000\nEpoch 114/200\n391/391 [==============================] - 118s 303ms/step - loss: 0.0086 - top_1_accuracy: 0.9975 - top_5_accuracy: 1.0000\nEpoch 115/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0121 - top_1_accuracy: 0.9966 - top_5_accuracy: 1.0000\nEpoch 116/200\n391/391 [==============================] - 119s 304ms/step - loss: 0.0089 - top_1_accuracy: 0.9975 - top_5_accuracy: 1.0000\nEpoch 117/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0103 - top_1_accuracy: 0.9971 - top_5_accuracy: 0.9999\nEpoch 118/200\n391/391 [==============================] - 118s 303ms/step - loss: 0.0111 - top_1_accuracy: 0.9969 - top_5_accuracy: 1.0000\nEpoch 119/200\n391/391 [==============================] - 118s 303ms/step - loss: 0.0123 - top_1_accuracy: 0.9968 - top_5_accuracy: 1.0000\nEpoch 120/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0126 - top_1_accuracy: 0.9962 - top_5_accuracy: 1.0000\nEpoch 121/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0119 - top_1_accuracy: 0.9968 - top_5_accuracy: 0.9999\nEpoch 122/200\n391/391 [==============================] - 118s 303ms/step - loss: 0.0112 - top_1_accuracy: 0.9967 - top_5_accuracy: 1.0000\nEpoch 123/200\n391/391 [==============================] - 119s 304ms/step - loss: 0.0110 - top_1_accuracy: 0.9974 - top_5_accuracy: 1.0000\nEpoch 124/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0083 - top_1_accuracy: 0.9976 - top_5_accuracy: 1.0000\nEpoch 125/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0080 - top_1_accuracy: 0.9975 - top_5_accuracy: 1.0000\nEpoch 126/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0091 - top_1_accuracy: 0.9975 - top_5_accuracy: 0.9999\nEpoch 127/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0092 - top_1_accuracy: 0.9973 - top_5_accuracy: 1.0000\nEpoch 128/200\n391/391 [==============================] - 118s 303ms/step - loss: 0.0109 - top_1_accuracy: 0.9971 - top_5_accuracy: 1.0000\nEpoch 129/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0153 - top_1_accuracy: 0.9960 - top_5_accuracy: 1.0000\nEpoch 130/200\n391/391 [==============================] - 119s 304ms/step - loss: 0.0083 - top_1_accuracy: 0.9975 - top_5_accuracy: 1.0000\nEpoch 131/200\n391/391 [==============================] - 118s 303ms/step - loss: 0.0066 - top_1_accuracy: 0.9983 - top_5_accuracy: 1.0000\nEpoch 132/200\n391/391 [==============================] - 118s 303ms/step - loss: 0.0028 - top_1_accuracy: 0.9990 - top_5_accuracy: 1.0000\nEpoch 133/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0015 - top_1_accuracy: 0.9994 - top_5_accuracy: 1.0000\nEpoch 134/200\n391/391 [==============================] - 118s 303ms/step - loss: 0.0105 - top_1_accuracy: 0.9972 - top_5_accuracy: 1.0000\nEpoch 135/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0185 - top_1_accuracy: 0.9950 - top_5_accuracy: 0.9999\nEpoch 136/200\n391/391 [==============================] - 118s 302ms/step - loss: 0.0170 - top_1_accuracy: 0.9956 - top_5_accuracy: 1.0000\nEpoch 137/200\n 48/391 [==>...........................] - ETA: 1:37 - loss: 0.0054 - top_1_accuracy: 0.9984 - top_5_accuracy: 1.0000","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_24/2389190331.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                   \u001b[0mlogdir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/checkpoint'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                   \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_top_1_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                   \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m               ),\n\u001b[1;32m     31\u001b[0m               \u001b[0;31m#TerminateOnNaN(),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m    134\u001b[0m     return concrete_function._call_flat(\n\u001b[0;32m--> 135\u001b[0;31m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    381\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 53\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"%load_external tensorboard","metadata":{"execution":{"iopub.status.busy":"2023-05-03T22:07:11.754082Z","iopub.execute_input":"2023-05-03T22:07:11.754988Z","iopub.status.idle":"2023-05-03T22:07:11.761926Z","shell.execute_reply.started":"2023-05-03T22:07:11.754934Z","shell.execute_reply":"2023-05-03T22:07:11.760531Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"UsageError: Line magic function `%load_external` not found.\n","output_type":"stream"}]},{"cell_type":"code","source":"%tensorboard --logdir ./logs/fit","metadata":{"execution":{"iopub.status.busy":"2023-05-03T22:07:17.311551Z","iopub.execute_input":"2023-05-03T22:07:17.311944Z","iopub.status.idle":"2023-05-03T22:07:17.318777Z","shell.execute_reply.started":"2023-05-03T22:07:17.311910Z","shell.execute_reply":"2023-05-03T22:07:17.317088Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"UsageError: Line magic function `%tensorboard` not found.\n","output_type":"stream"}]},{"cell_type":"code","source":"res = model.evaluate(x_test, y_test)\n\nprint(res)","metadata":{"execution":{"iopub.status.busy":"2023-05-03T22:07:23.754505Z","iopub.execute_input":"2023-05-03T22:07:23.755148Z","iopub.status.idle":"2023-05-03T22:08:06.348587Z","shell.execute_reply.started":"2023-05-03T22:07:23.755101Z","shell.execute_reply":"2023-05-03T22:08:06.347325Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"313/313 [==============================] - 24s 71ms/step - loss: 2.3906 - top_1_accuracy: 0.7333 - top_5_accuracy: 0.9184\n[2.3906383514404297, 0.733299970626831, 0.91839998960495]\n","output_type":"stream"}]}]}